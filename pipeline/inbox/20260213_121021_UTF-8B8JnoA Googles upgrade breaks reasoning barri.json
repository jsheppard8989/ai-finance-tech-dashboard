{
  "subject": "=?UTF-8?B?8J+noA==?= Google's upgrade breaks reasoning barriers",
  "sender": "The Rundown AI <news@daily.therundown.ai>",
  "date": "Fri, 13 Feb 2026 11:08:51 +0000 (UTC)",
  "content": "^**[Read Online](https://www.therundown.ai/p/googles-upgrade-breaks-reasoning-barriers?_bhlid=4eaa234680798ad3bdb45514b5705f029891f88c&jwt_token=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJzdWJzY3JpYmVyX2lkIjoiYzNlMzY5NWYtNjJlOC00YjBhLTg3MTgtN2NmYzcxMGFhMGM3IiwicHVibGljYXRpb25faWQiOiI0ZDAzMzkwZC0yNDgxLTQyOTktYjk0OS1mZmQ4YjM4YjRjMzgiLCJhY2Nlc3NfdHlwZSI6InJlYWQtb25seSIsImV4cCI6MTc3MTE1MzcxOSwiaXNzIjoiaHR0cHM6Ly9hcHAuYmVlaGlpdi5jb20iLCJpYXQiOjE3NzA5ODA5MTl9.pZgn_--P796onjVxgh8NtFHcmfZOC8hl0HiXKA2VENY)**^^ | ^^**[Sign Up](https://www.therundown.ai/subscribe)**^^ | ^^**[Advertise](https://therundownai.typeform.com/to/kraZ1TSO)**^\r\n\r\n----------\r\nView image: (https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/1b45be4c-0639-47b4-9f6e-9a701297aaa7/voxel51-new.jpg?t=1770929154)\r\nFollow image link: (https://link.voxel51.com/the-rundown-HA-webinar/)\r\nCaption: \r\n\r\n\r\n----------\r\n\r\n----------\r\n**Good morning, AI enthusiasts.** OpenAI and Anthropic have been grabbing all the 2026 headlines \u2014 but Google just reminded everyone why it's still the biggest powerhouse in the AI race.\r\n\r\nWith an upgraded Deep Think obliterating benchmarks across math, coding, and science, and a new research agent autonomously solving open problems, the tech giant is pushing frontier AI for scientific research into uncharted territory.\r\n\r\n\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\r\n\r\n**In today\u2019s AI rundown:**\r\n\r\n* Google's Deep Think crushes reasoning benchmarks\r\n\r\n* OAI launches ultra-fast coding model on Cerebras chips\r\n\r\n* How to generate a TV commercial with AI\r\n\r\n* MiniMax's open-source M2.5 hits frontier coding levels\r\n\r\n* 4 new AI tools, community workflows, and more\r\n\r\n\r\n----------\r\n\r\n----------\r\n**LATEST DEVELOPMENTS**\r\n\r\n\r\n----------\r\n\r\n----------\r\n###### GOOGLE\r\n\r\n#### **\u26a1**[_**Google&#39;s Deep Think crushes reasoning benchmarks**_](https://blog.google/innovation-and-ai/models-and-research/gemini-models/gemini-3-deep-think/)\r\n\r\nView image: (https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/f7ca6186-bd58-410b-8653-a3027a8f7ae9/deepthink.jpg?t=1770928318)\r\nCaption: Image source: Google\r\n\r\n**The Rundown: **Google just [released](https://blog.google/innovation-and-ai/models-and-research/gemini-models/gemini-3-deep-think/) a major update to its Gemini 3 Deep Think reasoning mode, posting dominant scores across math, coding, and science \u2014 while also introducing its Olympiad-level math research agent driven by the new upgrade.\r\n\r\n**The details: **\r\n\r\n* Deep Think hit 84.6% on ARC-AGI-2, obliterating Opus 4.6 (68.8%) and GPT-5.2 (52.9%), and set a new high of 48.4% on Humanity's Last Exam.\r\n\r\n* It also reached gold-medal marks on the 2025 Physics & Chemistry Olympiads and scored a 3,455 Elo on Codeforces, nearly 1,000 points above Opus 4.6.\r\n\r\n* Google also [unveiled](https://deepmind.google/blog/accelerating-mathematical-and-scientific-discovery-with-gemini-deep-think/?utm_source=x&utm_medium=social&utm_campaign=&utm_content=) Aletheia, a math agent that autonomously solves open problems, verifies proofs, and hits new highs across domain benchmarks.\r\n\r\n* The Deep Think upgrade is live for Google AI Ultra subscribers in the Gemini app, with API access open to researchers via an early access program.\r\n\r\n**Why it matters: **After Google dominated benchmarks and headlines to close 2025, the focus has been more on Anthropic and OpenAI in 2026 \u2014\u00a0but don\u2019t forget about the tech giant as arguably the biggest powerhouse in the AI race. Deep Think\u2019s scores are wild, and the frontier for math and science is quickly moving into uncharted territory.\r\n\r\n\r\n----------\r\n\r\n----------\r\n###### TOGETHER WITH VOXEL51\r\n\r\n#### \ud83d\udcb8 **[_Stop wasting 95% of your data labeling budget_](https://link.voxel51.com/the-rundown-HA-webinar/)**\r\n\r\nView image: (https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/6be0cd36-a45a-4a01-8617-9710f98d4cf0/image2__15_.jpg?t=1770920050)\r\nFollow image link: (https://link.voxel51.com/the-rundown-HA-webinar/)\r\nCaption: \r\n\r\n**The Rundown:** Most teams are labeling massive amounts of data that never gets used for model training. Voxel51's technical workshop on Feb. 18 shows how to build feedback-driven annotation pipelines that eliminate over-labeling \u2014 saving time and money while improving model performance.\r\n\r\n**Join the workshop and learn:**\r\n\r\n* How to use zero-shot selection and embeddings for maximum cost savings\r\n\r\n* QA workflows to review specific objects and fix errors fast\r\n\r\n* How to implement dedicated test sets to catch label drift early\r\n\r\n* Debugging with embeddings to visualize the clusters confusing your model\r\n\r\n_[Register now](https://link.voxel51.com/the-rundown-HA-webinar/)_.\r\n\r\n\r\n----------\r\n\r\n----------\r\n###### OPENAI\r\n\r\n#### \u26a1 **[_OAI launches ultra-fast coding model on Cerebras chips_](https://openai.com/index/introducing-gpt-5-3-codex-spark/)**\r\n\r\nView image: (https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/01c06635-6f08-4883-b15f-c560725c6f28/spark-codex.jpg?t=1770926178)\r\nCaption: Image source: OpenAI\r\n\r\n**The Rundown: **OpenAI [released](https://openai.com/index/introducing-gpt-5-3-codex-spark/) GPT-5.3-Codex-Spark, a new speed-optimized coding model that runs on Cerebras hardware, cranking out 1,000+ tokens per second and marking the company's first AI product powered by chips beyond its Nvidia stack.\r\n\r\n**The details:**\r\n\r\n* Spark trades intelligence for speed, trailing the full 5.3-Codex on SWE-Bench Pro and Terminal-Bench but finishing tasks in a fraction of the time.\r\n\r\n* The release comes just weeks after OAI inked a $10B+ deal with Cerebras and separate agreements with AMD and Broadcom, diversifying away from Nvidia. \r\n\r\n* OAI's vision is for Spark to handle quick interactive edits while the full Codex tackles longer autonomous tasks in the background.\r\n\r\n* The model is rolling out as a research preview for ChatGPT Pro subs, with API access initially limited to a handful of enterprise design partners.\r\n\r\n**Why it matters: **Codex's main criticism has been its speed, and OpenAI just addressed it in a big way \u2014\u00a0while making its chip diversification play real with the first product built on Cerebras hardware. Real-time coding with instant feedback will definitely change workflows for development tasks that are able to compromise a bit of power for speed.\r\n\r\n\r\n----------\r\n\r\n----------\r\n###### AI TRAINING\r\n\r\n#### \ud83d\udcfa\u00a0**_[How to generate a TV commercial with AI](https://app.therundown.ai/guides/how-to-generate-a-tv-commercial-with-ai)_**\r\n\r\nView image: (https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/9d84e280-68ef-43e1-a893-b10dec7674c9/Gemini_Generated_Image_j7e35cj7e35cj7e3.png?t=1770933696)\r\nCaption: \r\n\r\n**The Rundown:** In this guide, you will learn to generate a 20-second ad in the style of a professional TV commercial \u2014 taking the guesswork out of outputs without needing to click and pray.\r\n\r\n**Step-by-step:**\r\n\r\n1. Think of a commercial idea and ask Gemini to plan out two 5s scenes. Once done, ask it to write prompts for the start and end frames of both scenes. \r\n\r\n2. Now, log in to [Higgsfield](https://Higgsfield.ai) (you will need a basic/pro plan) and click Image > Create Image > Nano Banana Pro. Set 4k quality, 4 variations, and 21:9 ratio.\r\n\r\n3. Generate the start + end frame for scene 1 and just the end frame for scene 2. Download the ones you like best.\r\n\r\n4. In Higgsfield, go to Video > Kling 3.0, upload your frames with the short scene prompt, and hit generate. After this, stitch the videos in a free editor.\r\n\r\n**Pro tip:** Ask Gemini to use photography terms like \u201cHero shot\u201d when generating scene prompts. You can also generate music for the ad with Suno + Eleven Labs.\r\n\r\n\r\n----------\r\n\r\n----------\r\n###### PRESENTED BY CDATA\r\n\r\n#### \ud83c\udfd7\ufe0f **[_Build secure agentic AI that scales_](https://www.cdata.com/resources/workshop-build-copilot-agent-with-microsoft/?utm_source=rundown&utm_medium=newsletter&utm_campaign=26Q1_Microsoft_Copilot_Webinar)**\r\n\r\nView image: (https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/2ac2871f-52d6-4150-ba8e-06e364d22373/image1__46_.png?t=1770920131)\r\nFollow image link: (https://www.cdata.com/resources/workshop-build-copilot-agent-with-microsoft/?utm_source=rundown&utm_medium=newsletter&utm_campaign=26Q1_Microsoft_Copilot_Webinar)\r\nCaption: \r\n\r\n**The Rundown:** Microsoft and CData are teaming up for a live 45-minute session on how to design secure, scalable agentic infrastructure using Copilot Studio, Agent 365, and CData's Connect AI \u2014 including a live cross-system workflow demo.\r\n\r\n**In this session, you'll learn:**\r\n\r\n* How Microsoft and CData deliver connectivity, context, and control for production AI agents\r\n\r\n* Agent design and production best practices from both teams\r\n\r\n* How a Copilot Studio agent syncing with Salesforce and Dynamics 365 is built and deployed\r\n\r\n_[Register here for the session](https://www.cdata.com/resources/workshop-build-copilot-agent-with-microsoft/?utm_source=rundown&utm_medium=newsletter&utm_campaign=26Q1_Microsoft_Copilot_Webinar)_. All registrants will receive the session recording.\r\n\r\n\r\n----------\r\n\r\n----------\r\n###### MINIMAX\r\n\r\n#### **\ud83d\udcb0 **[_**MiniMax&#39;s open-source M2.5 hits frontier coding levels**_](https://www.minimax.io/news/minimax-m25)\r\n\r\nView image: (https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/7ed4cb1b-9a7c-4db4-9ba3-a1c2dab2f903/minimax25.jpg?t=1770934024)\r\nCaption: Image source: MiniMax\r\n\r\n**The Rundown: **Chinese AI lab MiniMax [launched](https://www.minimax.io/news/minimax-m25) M2.5, an open-source model that rivals Opus 4.6 and GPT-5 on agentic coding benchmarks \u2014 but at a fraction of the cost, making it",
  "content_preview": "^**[Read Online](https://www.therundown.ai/p/googles-upgrade-breaks-reasoning-barriers?_bhlid=4eaa234680798ad3bdb45514b5705f029891f88c&jwt_token=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJzdWJzY3JpYmVyX2lkIjoiYzNlMzY5NWYtNjJlOC00YjBhLTg3MTgtN2NmYzcxMGFhMGM3IiwicHVibGljYXRpb25faWQiOiI0ZDAzMzkwZC0yNDgxLTQyOTktYjk0OS1mZmQ4YjM4YjRjMzgiLCJhY2Nlc3NfdHlwZSI6InJlYWQtb25seSIsImV4cCI6MTc3MTE1MzcxOSwiaXNzIjoiaHR0cHM6Ly9hcHAuYmVlaGlpdi5jb20iLCJpYXQiOjE3NzA5ODA5MTl9.pZgn_--P796onjVxgh8NtFHcmfZOC8hl0HiXKA2VENY)*",
  "extracted_tickers": [
    "NVDA",
    "MSFT",
    "GOOGL"
  ],
  "ingested_at": "2026-02-13T12:10:21.557695"
}