A large number of departures from X-A-I from the founding team.
It wasn't clear to me whether they were fired or whether they left, you know, because they'll leave on good terms.
I don't know the answer to that question.
I will say that it's, um...
The cursive self-improvement RSI is the real trigger for the singularity, and it happened a while ago.
We're exiting the industrial age permanently, as we're talking.
We're obviously going into a new world, like with the industrial revolution.
I think it's scary at times to think about.
I think we have 150,000 people per day dying on Earth, and I think A-I is probably the best chance we have at stopping that.
Whoever is building the A-I has a lot of control about how society is going to work.
So I do think there's real danger along these lines of attempting to pause it.
When are we going to have discovery by an A-I of something as significant as relativity on its own?
I don't think it's the next 12 months, I think it's...
Now that's the moon shot, ladies and gentlemen.
So everybody, welcome to Moonshots, another episode of WTF here with my Moonshot Mates.
D-B-2-A-W-G, Mr. E-X-O, and a friend of the pod, someone who's been with us before.
The amazing Ben Harwitz of, and recent Harwitz Ben, where are you today?
I am in Las Vegas today, actually. It is my wife's 60th birthday weekend, super celebration, so...
Oh, happy birthday.
Oh, we're getting immersed out with the long-tenth day?
Yeah, yeah, yeah, yeah.
You get to say that.
It's just a good news, bad news.
Well, last time I was in Vegas, we can cut this from the pod if we need to.
But last time I was in Vegas, I told my mom, hey, I'm in Vegas.
She's in her mid-80s, and she said, oh, you're in Vegas, did you shoot your wad?
Is that a phrase?
She's like, wouldn't it?
I mean, did you lose all your money?
Yeah, well, she clarified that.
Thank you for clarifying, Mom.
Yeah, that would have been a very aggressive question from your mom.
Yeah, that didn't stand the test of time, that particular phrase.
Well, as I like to say, but we welcome to the number one podcast in AI and exponential tech.
Our job here is getting you future ready.
And it is in the same week we've actually recorded two podcasts this week, just because the speed is over the top.
And we're going to be recording it another four days.
I mean, it's like, it's like, it's good, my goodness, right?
Thank God my AI avatar is getting really good.
Yeah.
Let's open up with top stories, invoices, video, X-A-I, Maltese.
Alright, first one.
Here we go.
We're starting to see a little bit of doomer conversations coming.
AI disruption will soon hit sooner than most expect.
This is something that's been making the rounds for Matt Schumer, CEO of other side AI.
Ben, have you seen this article?
Yeah, of course.
Of course.
Yeah.
Thoughts.
So, I mean, is this what we already know?
I mean, we're about to hit recursive self improvement.
Once that hits all of our curves go out the window, everything accelerates.
Everything we've been preparing for is being redefined on you time scales.
What do you think of it?
I think it's, I think the AI timeline is somewhat unpredictable, but kind of certainly more predictable than what he's.
Talking about which is societal change.
Yeah.
I think that, you know, it tends, I would be like very surprised just in seeing how even companies in Silicon Valley have changed so far.
If companies like outside of that sphere, you know, just completely change everything they did in one to five years.
Like, I think that's a little aggressive versus societal change.
You know, look, obviously going into a new world.
And, you know, like with the industrial revolution, I think it's scary at times to think about.
But, you know, like, there are going to be, he kind of, I feel like highlighted all the negative changes and not the positive ones.
And I feel like there's way more positive change coming than the negative change at a much more rapid rate.
So, I don't know, I like, like I thought it was a little aggressive.
I mean, I'm just trying to understand why it made the rounds since this is not the brand new conversation.
But I got it sent to me by everybody. Dave or Alex?
I think it, I think it really has to do with open claw and, you know, kind of the new coding models.
So, people in Silicon Valley are talking about AI differently since then because it is kind of different.
And I think that that's a trigger for this one being so viral.
Yeah, I completely agree.
I think a lot of things that we've been saying for, you know, up to a year now on the pod are suddenly resonating a lot more because of, you know,
open claw, but also a bunch of other eye-opening nanobinanotype things where, you know, denial a year ago is very easy.
Denial today is much, much harder.
It's like what's right in front of you.
But also the flavor of this rollout has changed a lot in my mind recently because, you know, this was board meeting week for me.
You know, three back to back mega board meetings, 1100 people affected.
And what they were thinking of before was, well, will AI be able to do what I do and replace me?
No way.
Now they're like, oh wait, AI is easily going to make me three times more productive.
Okay, well, that's the same thing, right?
In terms of the head count, you need to get a job done.
That's effectively the same thing.
And like, okay, I didn't think of it that way.
Now you're exactly right.
So the hope is that these companies will grow into it and can keep current head count and expand 3x.
But if you don't expand 3x, you're still looking at, you know, a two-thirds reduction in head count to get the same job done.
So it effectively is a huge amount of displacement.
Because, you know, big, big banks and insurance companies are not going to triple their size in the time for real.
Yeah, I also think they're not going to go to total efficiency very fast.
Like, I mean, I could be wrong, but like I've dealt with these guys.
They've had plenty of opportunities to be more efficient.
And we'll see.
We'll see.
We'll see.
I'll see.
I'll just keep the thoughts about that.
Yeah, please.
Good.
One, I thought it was like a summary of the podcast for the last eight months.
That's all we've been talking about is stuff's going to change.
It seemed a little dramatic, as Ben put it.
And I don't agree with the timelines.
But definitely, there was something coming.
I think it's just a quiet.
The reason it's making the rounds, it's just got the zeitgeist of what's exactly happened.
That's exactly happening that we need to track right now, which is we're in a singularity of multiple types.
So that's what I got.
By the way, I'll show you.
Also, like super well written, like a really competitive written.
Just thinking I read.
Yeah, yeah.
Yeah.
I'll chime in here and just say, while I enjoy writing about the singularity in general, obviously,
I'm doing it almost every day at this point.
I found it completely unremarkable.
Maybe I'm just too deep in the weeds of writing about more pressing advances every day.
But the sort of style where you talk about advances that by the way, moving even more quickly,
then I think described in the essay and comparing it back to the COVID pandemic, which I think is a relatable touch point.
For a lot of people like something big is about to happen.
Let's be really millennialist.
And if you read my essay, it's the ultimate viral hook of read my essay to know exactly what's about to happen.
And how to survive the next five minutes of your life.
It's a natural viral moment, but I don't think the information value was especially high compared to others.
I agree.
Exactly what I said except Alex said it more eloquently.
Yeah.
Yeah.
Everybody, you may not know this, but I've been an incredible research team.
And every week, myself, my research team study the meta trends that are impacting the world.
Topics like computation sensors, networks, AI, robotics, 3D printing synthetic biology.
And these meta trend reports I put out once a week, enabling you to see the future 10 years ahead of anybody else.
If you'd like to get access to the meta trends newsletter every week, go to dmds.com slash meta trends.
That's dmds.com slash meta trends.
We have a couple of articles here on C Dance 2.0 out of bite dance.
Man, which is so good.
Oh, my God.
It's amazing.
It's, you know, it's going to change everything.
Let me play this particular video first.
The response here is, you know, and you've said this before Alex Hollywood is cooked.
Right.
So this is a video clip with a one line prompt.
Let's take a look ahead of it.
Oh, my God.
Just check it out.
So, you know, Tom and Brad fighting karate on a rooftop.
And it generates what 10 second clips right now.
Alex, what do your thoughts?
I think at the risk of sounding again a whole hum unremarkable,
we saw copyright infringement at the scale already,
or alleged, I should say, with earlier video models.
And we saw the industry response, and we saw settlements that eventually
deals were struck to handle it.
I think people are at this point.
Again, maybe I'm just sounding overly jaded with some of these advances,
but I've seen remarkable advances in video models.
I tend to think that people are so easily odd by video models that
that are able to show celebrity faces and scenes that they recognize
that maybe they overindex on the underlying quality of the models.
I think world models that are interactive and real-time are profoundly more interesting
than video models.
I think this is just 10 different copyright infringement lawsuits
waiting to happen.
But I still was wow.
I'm still with those people that say,
Yeah, I was amazing.
So I would say on this one,
the two videos that I watched that were like,
like, were the entertainment quality,
which so high were one that Kanye doing his song in Chinese
was so good that video, like, watch it three times,
as that entertaining.
And then the other one was the Waffle House one.
And they're both kind of, I would just say,
representative almost of a new medium.
It's not like, okay, this is film generated by AI.
It's like, this is a whole other thing that we've never seen before.
So I think this model is,
at least for me personally as a consumer was an impressive step up.
But I think, well, also YouTube wins in this model, right?
Because there is going to be producing so much content
and it's going to become resonant on YouTube.
It's not going to, a lot of it may not go to the theaters
or television and so forth.
Yeah, Dave, you want to say?
Yeah, I was going to say the same thing like TikTok,
also is the big winner when you personalize the content
when it's almost movie quality.
And it's personalized to very narrow topic areas
and very narrow interests and many languages around the world
and everything else.
It just takes over.
And so when the movie people say, well, look,
we're still a little bit better.
Yeah, but you're missing the bigger picture,
which is you don't need to be as better than a movie.
If you can push the production cost down to an individual producer,
then the volume goes through the roof.
But the narrow casting is just so much more compelling.
You know, something that you and only your group really care
about a lot and full movie format is so exciting.
Yeah, I mean, the elephant in the room here,
is this 2K quality, multi-scene video.
It just doesn't just threaten Hollywood.
It threatens the whole concept of video as evidence,
right, quart testimonies, journalism, political campaigns.
Yeah, I mean.
Well, and also, it's going to be real time, right?
Like, so then just any kind of security mechanic that you have
where you recognize the person the video or voice is shot
to hell.
Yeah.
Yeah, yeah.
Yeah, yeah.
Yeah, yeah.
Yeah, yeah.
Yeah, yeah.
Yeah, yeah.
Maybe just add, again, I think this is several months behind the bleeding edge.
I think video models have been approximately this good.
Yeah, sure.
You can upscale it.
You can increase the fidelity of the faces.
You can certainly use faces that you probably shouldn't be using.
We've been able to do this for months,
I think the frontier actually lies in being able to do this in real time
and being able to do this on a single modern and video GPU,
and being able to do this at a cost-effective speed.
And I think, again, I want to avoid over indexing on just video models
that produce two Hollywood celebrities fighting each other on a rooftop.
We were able to do that many months ago.
This already been thoroughly litigated.
We saw open AI strike deals with relevant movie studios for sorrow too.
We saw the Disney deal.
In some sense, I think past this where we are now.
I don't think that's the point.
I think the point is this is making it out into the, you know,
ecosystem of common users.
I think it's the notion that, yes, it's the cutting edge.
Yes, it was possible.
But now it's something that is going to grow in its utility
and its consumer base.
And then all of a sudden, you know, we've had, you know,
basically the democratization of film production for some time,
but it's now going 10x, 100x more.
I mean, I think that's the issue.
You're bringing up a really interesting point, too,
which is that, you know, our starting point for this journey
was probably auto-complete and code, you know, and like,
wow, that's incredible.
But then, you know, Alex and his newsletter has been tracking
every event along the way.
So nothing surprises him.
After spoilers, it's funny.
I'm so spoiled.
This is so, six months ago.
What do you think about it?
Well, I'm something though that Peter said,
like the thing that I do think is different.
I'm not any aspect of it, but it's the combination of,
that you could give it a one-line prompt and produce something
entertaining, isn't something that we were,
at least I hadn't seen at this level of entertainment.
So I think from a consumer product standpoint,
I suppose it's a technological standpoint,
which I agree on, it's kind of exciting.
For me, it was very, too, exactly what you're saying there Ben.
If the later your first exposure to AI,
the more of a holy crap moment it is,
because, you know, it's something, you know,
truly mind-boggling to the unexposed.
And you're still seeing that when you,
when you survey around at random in a city,
you're outside of San Francisco or Boston,
the exposure rate to AI is still very, very low,
shockingly low.
So even you said, first thing you see is so mind-blowing.
Yeah, for me, this was whole hum because, you know,
if you trace the trajectory of where we've been going,
you should expect to see this about now, even earlier.
So there's nothing radically magical about it.
Okay.
Yeah, I may hit a new group of users.
Yeah, people go, you guys, and another batch of people,
another batch of people goes, oh my god,
finally another segment falling over into the new world.
All right, great.
And let's more voices out there.
This is the plus side of also the Schumer, I say,
yeah, we know.
But the more voices that they're talking about,
this is the better because it looks salary the whole thing.
All right, let's get to the second bite-dance C-dance 2.0 article.
Here we have C-dance 2.0 was paused by bite-dance
after was found to recreate real voices from just facial photos.
I find that almost impossible.
Just from a facial photo, Alex, what did you learn about this?
I think there's something interesting here,
which is, as we start to scale data sets,
it is possible that we could start to see positive transfer
between modalities that's unexpected.
We've spoken in episodes past about people claiming that they're uploading
their whole genome into cloud and being able to generate
facsimiles of their face that resemble the real thing.
I do think it's possible that if all of YouTube and all of the
worlds video were uploaded into a single joint embedding model,
which is the foundational technology behind C-dance 2.0,
I do think it is conceivable that if we just aligned all
of the world's audio and spoken audio with all of the world's faces,
we would find some positive transfer between the two
and be able to reconstruct a reasonably high fidelity
of your voice from your face or your face from your DNA,
or some attribute from some other attribute.
I do think it is possible with enough scaling,
whether C-dance 2.0 actually achieved it,
or whether it was just a happy coincidence,
hard to tell at the stage.
What's interesting, though, is that they voluntarily stopped it.
They voluntarily shut it down, which is a great sort of move
by a typical hyperscaler.
But the reality is, once it's out of the bag,
once you know it can be done, it can't be uninvented,
so it's out there if in fact it works.
Yeah, totally.
So for, you know, by-dance is like Google,
they have to be cautious and conscientious.
They can't just, but then every time this happens,
the small startup then does it again right after,
and they don't care because they're a startup.
All right, I want to play this video clip from 11 labs.
You know, I think all of us have 11 lab voices
that we use for different projects and so forth.
But I was just blown away by this,
and it's the human-like quality, the cadence,
the hums and the us that come out of this.
So let's take a listen and discuss it
because this is a game changer for me.
I know what you're going to say,
Alex, it's been around for a while.
I'm not saying any advance.
But let's take a dive in.
Hey there, I'm Jennifer with 11 Airlines,
and how can I help you today?
Jennifer, my flight just got canceled
and I'm stuck here in Orlando.
I'm going to be missing my daughter's birthday.
This is ridiculous.
Yeah, I hear you,
and I'm so sorry about that.
Let's figure out what's going on, okay?
Could you please tell me which flight this was?
Yeah, this is flight md412.
Great, thanks.
Okay, just pulling that up now.
Okay, yeah.
So I don't know.
I'm moved by that both excited and frightened.
In a way that is, you know,
again, we're cooked in terms of,
you know, at my home,
our family picked a secret code word.
And again, everybody listening,
if you've not done this yet tonight at dinner
with your parents or your kids,
pick a secret code word.
If someone's asking you to do something
that is kind of unusual or crazy
that you don't expect,
you may be talking to an AI.
So,
Ben, I may not know this,
but we have a full year spouse challenge
for this calendar year.
First podcast listener who can,
if you have to fool your spouse for three minutes on a zoom call
and has to be a totally fake you.
You may have to just hold it and send it in.
Peter is always asking the,
the multis,
the open claw agents to dox him by calling him at home.
Yes, that's my,
that's my,
AI,
AI is arrived when an AI is calling me.
You know what happens?
They end up emailing me.
I get several emails probably per day at this point
from open claw agents asking me what Peter's number is.
It's hilarious.
When they call me and ask them where they got it from Alex.
That's right.
Maybe just a comment on the 11 labs.
So, if you've been using the version 3v3 alpha model
from 11 labs,
this should hardly be surprising.
V3 enables you if you use text to speech
in the 11 labs platform to specify
with brackets emotional expressions
and this has been around for many months.
What's somewhat interesting here to me at least
is we've known how to do audio to audio transfer
for probably a year plus at this point.
If you've used advanced voice mode from open AI,
you've used audio to audio transformers.
But what's somewhat interesting here is 11 labs
is better known for text to speech than speech to speech.
As far as I can tell,
this new expressive mode that we're talking about here
seems to still leverage the text modality,
which historically has been very difficult.
You'd have to go from speech to text back to speech,
which was high latency, it was slow.
It didn't feel very conversational and somehow
seems like without having to do direct audio
to audio, 11 labs has found a way to do speech
to text back to speech in a way that feels natural
and turn taking and real time.
So, I think it's in some sense an incremental advance,
but another sense if they really are still keeping text
which is much easier to to mind and analyze
and the loop probably is a material advance.
I would say we've crossed the uncanny valley on voice
at this point with this demonstration.
And then voice becomes the new interface in the AI era.
I mean, I can't tell you the amount of time
that I'm just speaking to AI versus this cumbersome typing at it.
So, I think those two things are really important
take away from this way.
I think that's a great way of putting a picture.
But the problem is, do you really want to use audio
as your primary model?
I mean, it works well.
It'll be your isolation.
Okay, yeah, you want BCO.
I want to BCO too.
And I want wearables.
And I want gestural interfaces.
I want it all.
But for most people, I mean, is it,
New York, this is sort of famous anecdote.
New York Times in the 1980s did a famous study
where they just put all of their reporters
on then state-of-the-art speech-to-text systems
and ask them to use voice.
And what happened was the writing quality went down.
Why did it go down?
Because it's difficult to think ahead
as well as you can when you're just typing
if you're speaking, you're leveraging
similar portions of the brain.
So, I'm not 100% sold yet.
That speech is the modality of the future.
I do like BCOs.
I do like wearables and gestural interfaces.
I do like typing.
But speech, I think jury is still out for me
for high band with operation.
Yeah.
You don't want to go there.
I'm just going to say, for regular people,
who don't necessarily write for the New York Times.
I think speech is often,
or at least in my experience,
is the mode of choice.
For sure.
The other thing I say about 11 labs
and kind of quick disclaimer that,
you know, we're a big investor in 11 labs and my daughter.
So, fear works there.
So, I'm...
If I start to...
But the...
You know, one of the really amazingly just kind of landscape
shocking things to me about 11 labs
was, you know, we invested originally.
The big question was, well, like,
aren't the, you know, state-of-the-art models
going to be able to talk.
I mean, like, of course, they're going to be able to talk.
But, you know, speaking correctly with the right nuance
and building the right products for developers
and so forth has proven to be very sustainable for them,
which I think is an interest thing
as you like at the entire landscape
that difference between the capability and the product
is significant.
Yeah, you know what's amazing to me about 11 labs.
We have two companies here in the lab
that do voice, voice, run, and Vokara.
And what's amazing is, yeah,
these are self-organizing systems that are trained
off raw data.
And what they do well just blows your mind.
But, you know, with voice it turned out the turn
management was very, very hard.
And you're like, well, I didn't ever thought
like it seemed so trivial compared to actually
doing these incredible synthetic voices
that can say intelligent things.
But they don't know when to stop talking.
You know, like on this podcast,
when I stopped, you start when you start.
It's like very natural to us.
But because that wasn't in the training data,
they're just, you know, up until now,
terrible at it.
Wait, according to our listeners,
we're talking about each other all the time
in a very unsynchronized voice.
We have so much to learn from these speech
to text and speech models have not been taken.
Yeah.
Oh, my God.
Yeah.
All right.
Next topic here.
If you guys okay with it, I'll move us along.
So just following the merger of SpaceX and XAI
and in the spirit of full disclosure,
I'm an investor in both probably,
probably yours.
Well, Ben, a large number of departures.
All three of the access.
Yes.
A large number of departures from XAI
from the founding team,
mostly ethnic Chinese co-founders.
And it's likely due to the
eye-tour regulations of SpaceX.
All right.
And it was interesting on a few,
a few video presentations
that Elon's done that's had the team from XAI
at least half of the team there with ethnic Chinese.
And, you know, the culture there
breeds incredible mathematicians and programmers.
Any comments?
Ben, I'd love to get your thoughts on this,
but I looked at the timeline and the
Exodus of senior AI talent predates
even the decision on who to merge with what.
So the theory that this is related to ITAR,
and I wasn't clear to me whether they were fired
or whether they left, you know,
because they'll leave on good terms.
I don't know if you have any insight.
Yeah, I don't know the answer to that question.
I will say that it's,
so in a related matter,
we like recently heard from a few Chinese
nationals who are PhD students
that the Chinese government is cracking down
the Americas or US academia's use
of Chinese open source models.
Like they particularly post the meta-manus acquisition.
They're very, very worried about
actually secrets going this way.
So kind of the opposite of what we've been worried about,
which they, you know, like our whole open source,
kind of work is based on the Chinese model
since there haven't been as many US open source models.
So that's a, this whole thing I think is about
to get more complicated.
If you read these tweets,
if you read these tweets,
you know, Mr. Wu and Mr. Bob both are super enthusiastic
about XAI. They're not leading with any kind of angst.
You know, they're saying that they love the XAI family.
We're heading towards an age of 100x productivity.
So I don't think they would have left
on their own accord. That's my personal opinion.
So what drove it?
You know, enter Alex's comment from last time
will win did their best, their stock best.
I mean, there is another explanation,
which is just SpaceX is a very large company relative
to XAI's head count,
and maybe there was a natural reorganization
that happened as a result of that.
I'll also point out that XAI
was selling foundation model services
to the Department of War prior to this merger.
So I would again query whether
some sort of nationality concern
is really the trigger.
It seems more likely to me this is just the result
of a natural re-work of XAI
starting to merge into SpaceX.
Yeah.
Well, if it were a result of ITAR
and such, you know,
their America's AI dominance
is really built significantly
immigrant talent.
So if we're going to start having
this kind of a reaction to, you know,
PhD immigrants, I mean,
I personally think,
and I'm curious what you think
that everybody going through a PhD program
in the U.S. should have a green card
stable to their PhD when they graduate.
I think the idea of kicking people out
is the wrong approach.
Yeah.
I think generally that's in general
that's correct.
I do think that there's,
I don't think we've quite thought
through the case of China totally
in that, like we have, you know,
amazing Chinese nationalists who work for us
and every company we have, I think.
Of course.
So, you know,
the talent that comes here is extraordinary.
I wouldn't say there is no risk
to that idea.
I guess I would just say that.
But I think being a,
I think you're right, general.
I think we should be open.
We should accept the phenomenal talent
that comes over here
and not fight it because what will
lose anyway?
I mean, like we're not keeping
anything secret in America.
Certainly not in American companies.
There's not going to have
skips.
None of them have good security
protocols around personnel.
Don't get me started on the,
on the idea that privacy is,
long since dead.
Yeah.
So, here's your correct.
Here's a tweet from
Jimmy Bach, a co-founder
at XAI.
Recurse yourself in
improvement loops likely to go live
in the next 12 months.
26 is going to be insane
and likely the busiest
and most consequential year
for the future of our species.
So, you're going to hear
it's like your time to go off.
This, I mean,
you're going to hear this a few times
that, you know, these next few years
are a massive
inflection point
that everything changes
and we're going to look back
thousands of years in the future
back to this,
this, you know,
inflection point.
Or is it just a smooth
singularity, Alex?
I think it can be both.
I think we've already
seen the era of Recurse
of self-improvement
on banging the table
rhetorically every episode
and every day in my newsletter
talking about Recurse
of self-improvement.
We're there.
All of the frontier labs
are using their own models
at this point to develop
their models.
That's practically
the definition of Recurse
of self-improvement
at this point in practice.
I don't think
it's the next 12 months
I think it's,
it's now.
And is
2020's going to be
insane relative
to years past
if you just sort of skip over
all of the interim time?
Absolutely.
Is it already
insane in some sense?
Absolutely.
Even if we just look at
the events of the past
24 hours,
some of which I,
I think we'll get to,
like self-replicating AI
and courts
where AIs can
mediate their own disputes
in front of an AI jury.
That would have been pure science
fiction several years ago.
That's not 12 months
from now.
It's not quote unquote
within the next 12 months.
That's the past 24 hours.
So I think if anything.
Yeah, that's like the past 24 hours.
So I think Jimmy is
underselling
if anything,
what craziness looks like
at the same time
locally,
space-time is smooth.
And you need to look
no further than
my saying,
whole hum,
to a few of these stories
as being so several months ago
that would have been sci-fi
years ago.
But you get a little bit
spoiled living
inside the interim Muslim.
Let's say I do think
there's
delineation
between recursive self-improvement
with a human
in the loop
and without one.
And I think
he seemed to be
complying that there
would be no human in the loop,
which I think
is an accelerant.
You know,
TBD
how much of an accelerant,
but I think that
could be very different.
Yeah,
permissionless self-improvement.
Like,
flip the switch and go as fast
as you can.
Well, also,
there's a distinction
in this came up
at the Ebroquo Board
meeting yesterday,
but the
self-improvement
where the
inference time speed
algorithms
are being improved
by AI
clearly
well underway
way down the path.
And then
inference time speed
can be directly
translated
into intelligence now.
We now have
the know-how
to turn
more inference time loops
into a higher IQ.
So
that is clearly
underway.
So,
because that
not
up,
then allow it to work
on the next part of the
algorithm,
the next part of the algorithm,
which case we've already
hit the flashpoint.
And now we're just talking about
the rate
at which it percolates across,
but then I agree
that his comment
is about
the actual core
algorithm development.
The next ideas
are 100%
from AI.
And then they go into production.
You know,
I also think human
outside the loop
of the theory or
slippery slope.
If you remember
George Jetson from
the Jetsons.
George,
that had to remember
George.
Remember George Ben.
George would go into work
and he would complain
about his finger.
He'd have to press
one button all day
with his finger.
And then
complain that his finger
was sore.
And the finger
would be swollen
from pressing a single
button all day
occasionally.
I think that's like
that does a good
metaphor for the
state of recursive
self-improvement
outside the frontier
labs right now,
where you have
clawed code instances
and
Claude is asking you
every few minutes.
Do I have your
permission to do the
following thing?
And you press the
George Jetson button.
Yes, I approve.
No, I don't approve.
And we're all
sitting here
complaining about our
swollen finger
from pressing a
approve
or approve
for Claude
running
Opus 4.6 with agent
teams.
But really,
I think we're in the loop
by pressing the George
Jetson button.
Exactly.
What I'm doing on
telegram right now
with my with
skipie.
Yes.
Go on to the next
stage.
I don't want to
be.
I don't want to slow things
down.
And as we've said
so many times,
this is the slowest
and most expensive
it's ever going to be.
Look at that.
This is a couple of
points here.
Yes.
It's we've been talking
for a while that
recursive self-improvement
and that's
a way to
figure for the
singularity.
And it happened
a while ago.
So all we're doing now
is accelerating that path.
We're exiting the
industrial age permanently
as we're talking.
Yeah.
I really think
the minute by minute
unfolding
of the singularity is
the most fascinating thing
I've ever experienced.
And you know,
Alex is exactly right.
There's this point in time
we're in right now
where there's a human
that's really ambiguous.
What part of the
of the progress is AI
versus human?
You know,
if you're in the
actual coding process,
you know,
was that my idea?
I kind of was half my idea,
but then the AI suggested
this other thing.
And I kind of adopted it.
And now
it's not clear
whether it was my idea
or not.
But we're in that
mode right now
where the research,
you know,
a lot of the research
in these core algorithms
is just deploy
these 500 tests for me
and tell me which
hyperparameters worked better
which, you know,
neural topology worked better.
It's not like
inventing,
you're discovering
relativity, you know,
it's just
litanys of experiments
with different,
you know,
different trials.
And then
taking the one
that worked and
redeploying it,
and now you have
a smarter AI.
And now it's trying
more trials.
It's really
very likely that we're
well down that path.
And I don't want to
so I do think we're
going to discover
the next
relativity or
equivalent of relativity
in physics as well with AI.
I'm prediction
for interested in
that as well.
Prediction.
What would you like
to hear?
Next relativity.
When are we going to have
discovery by an AI
of something
as significant
as relativity
on its own?
I think next two years.
Okay.
Yeah,
I would also
this is a great
Bellweather.
The transformer algorithm
2017 that kicked off
everything that we're
experiencing right now.
To me,
the AI's already
discovered things
in the last six
months that are harder
to discover and
harder to solve
than the transformer was.
But
I'll ask you, Alex,
if you feel like
that's true too,
but it seems pretty clear to me
that absolutely
I think just not.
I mean,
so it's not up there with
relativity in terms of
complexity.
Well,
I mean,
I guess everything
many of these
discoveries boil down
to insights
that can be distilled
down into equations
and you can
in principle with
relativity with
special relativity.
You can do
a number of
thought experiments.
You can compare it
fortunately with
lots of experimental data
and one could
imagine a thought
experiment.
One of my favorite
thought experiment is
a Bayesian super intelligence.
So if you had
like a video of
this would be
Newtonian gravity
not special relativity,
but you could
imagine
taking a super
intelligence
making it
more
interesting.
The
argument in the thought
experiment goes
within three
frames of that
video,
it should have
concluded
Newtonian gravity
is a pretty
high likelihood
posterior probability
of
be of explaining the
universe.
And with a few more
frames,
somewhere in its distribution
and this,
there's a whole
class of
information theory devoted
to what's called
the
experiment.
So
I'm
incredibly
bullish that
will be able to
with super
intelligence discover
any new laws of
physics,
discover
transformative
inventions.
For disclosure
purposes,
we're playing the disclosure
game.
I have a portfolio company
physical super intelligence
that's working on
these issues as well.
Very bullish on this
experiment.
I've
pulled a clip out of it
and the question that we've
talked about on the
pod before.
It's been the debate.
Can AI be paused?
The answer
quite clearly
by almost
everybody today is
no.
We had that
conversation
Dave,
you and I
with Elon.
Let's take a look at
what Eric has to say.
This technology is going to
happen.
It's not going to get
prevented.
It's not going to get
to happen.
It's going to happen.
So what's
this mean?
It means
great
solutions for
health care
new drugs
better energy
solutions better
power distribution.
It also means
that it can be used
for bad.
You can be used for example
for oppression.
It can be used
to limit
freedom in governments.
Hopefully not
in the west.
It can be used in
war.
The technology itself
is so
that it can affect our
young people.
And we should make sure
that our young people
are protected
from some of the worst parts
of the technology.
We face choices now
how we
want to deal with this
incredibly powerful
technology.
I will tell you
and it's really
important to understand
that we are
living through a
moment that will be
in history
for thousands of years.
And nonhuman
intelligence
arrived.
And it was a
competitor to us.
Amazing.
We hold two
futures in
which AI is the greatest
advocate
and supporter
and accelerant
to human spirit.
Another
future where
it is a dystopian
outcome.
And it's ours to shape
at these next few
years.
Dave, you're going to
say.
Oh,
Alex and I were there
in the dome.
You know,
that was our
double stone
where he was speaking.
And it just blows
my mind how he owns
a room.
The guy is so
articulate.
He's going to be
going into a lot of this
conversation.
Dave, you and I are going to be
on stage.
Well, what he's
describing in that
clip was very similar.
We did a whole interview
of him, which you
can find on YouTube.
And yeah, he made that
point in our interview
of him as well.
That there's no
force that's going to slow
this down.
And so all the people
picketing and walking
around saying stop it.
You're just wasting your
time.
You're just going to
point it toward good.
But picketing with us with a
sign on the street is a
complete waste of your
time.
It's not going to slow down.
Sorry, Alex.
Okay. Yeah.
I would take the
position.
I think AI
in fact can be
paused, but it
shouldn't be.
We do know ways to
pause it.
Various folks have
described both in science
fiction and in realistic
precnostication.
In some case,
normative recommendations.
The
question is,
are there any
lines maybe in the case of
recombinant DNA?
Those were guiding.
Not
pausing.
Well,
a silamar was
unless you know
of some other story,
pretty effective for
the first two
decades in discouraging
slash pausing,
recombinant DNA
entering the human
germline.
Unless you have
account for example.
It was, it was just the,
what did we
pause human germline
editing for sure.
Yes.
So we are capable of
pausing
a technology.
If there is a
desire to,
I just think in the case of
AI,
there isn't
an arguably
shouldn't be a
desire to pause it.
I think we have
150,000 people per day
dying on earth.
And I think AI
is probably the best
chance we have at
stopping that.
That's a question.
I hope
how
wonderful
essay that I recommend everyone
read called optimal timing for
super intelligence.
Argyz that AI can and
should be paused,
but only once we are on
the verge of super
intelligence,
how he defines it and how
I defined it.
I think it is already here,
that kind of like station
I think that sort of concept I think makes much more sense than some sort of tech
marquee and six month pause.
I'm sorry I'd like to throw in a couple of things here.
I find this is another whole hum thing.
Yeah, Eric is fabulously articulate.
But we've been saying this for months on this a year at least now.
We've been talking about the fact.
And there's a bunch of dimensions that AI cannot be paused at all.
One is once you have a downloaded model,
people are going to do stuff with it.
We have a global president and there's the lemma model going on here.
The whole thing is going to scale now.
No matter what we do.
You know, opening I did two things that that kind of unlocked this Pandora's box.
One, it wrote code and the second it was released on the open internet.
Once you do those things, you're done.
Pandora's box is gone.
We're talking about the barn door after the horses bolted.
We're using an 18-century metaphor to try and understand what's going on.
I think what the point he made was everybody's economically incentivized to keep it going
and race it along.
And the US China, you know, it's like all the incentives are in place
that make it highly improbable and almost impossible.
Ben, what are your thoughts possible?
Impossible.
So I think, you know, look at this question through the geopolitical lens,
which is, you know, clearly,
I don't think there's any kind of leverage where we would get some global,
I mean, especially when it's like people's laptops as well,
where we would actually stop the technology.
Like, I do agree that it's impractical.
I think that there is a real danger.
And we faced it probably more in the Biden administration than in this one.
But it's still like a potential movement that we really slow down AI progress
in the US to the point where the other thing that he mentioned in the threat to freedom
becomes completely out of our control.
Because whoever is building the AI has a lot of control about how society is going to work.
And so I do think there's real danger along these lines of attempting to pause it
and maybe not actually pausing it, but slowing it a dent down enough in the US
that we just become far enough behind China that it's a real problem.
Or like, we're whatever society, you know, the Xi Jinping thinks we should be.
Yeah, completely agree.
I think, you know, if you listen to Eric's words closely, he wasn't saying we couldn't pause it.
He's saying that because we're in the middle of a all-out arms race with China,
and we have only one year into a presidential administration.
So it's going to happen in this next three years.
So given the current administration and the current situation with China, there is no chance of it being paused.
And so react to the real reality.
Don't don't hypothesize something that is just never going to happen.
But it was all geopolitical like you said.
That's the motivation.
I'm speaking of the fact that there's no mechanism to pause it or stop it at all.
You have to read every line of code.
I mean, come on.
Oh, Salim, there are ways to do it.
I think not being able to think of it speaks well of your character.
You have to imagine a completely pathological society.
VenerVinci wrote quite a bit about this.
We have these excess transistor budgets.
Imagine a society where you have literally transistors spying on other transistors on a single
SOC.
Imagine you have people spying on other people.
Imagine there are bounties.
Anyone discovers anyone else doing something that's algorithmically impermissible either at the logical level or the social level.
You can construct a sufficiently pathological society where people are turned against each other.
In order to suppress AI, at least I can imagine it.
I'm speaking an actual real world example.
Let me give you a real world example.
The last executive order from the Biden administration was that you could not sell a GPU without US government approval.
Not a single GPU.
So like I think that would when stop AI, it would slow it down enough in the US that it would be extremely material.
Speaking of this subject, Alex put this slide up after our conversation.
Do you need to insert it this slide Ben as an indulgence to me?
So I have to ask you this question.
You and Mark towards the end of the last administration were very public making comments that you took a meeting at the White House.
A proposal and if I'm relaying the comments accurately, you were dismayed to hear about plans to classify AI progress just like,
and again correct me if I'm mischaracterizing.
Advances in math and fundamental physics had been purportedly classified or overclassified for decades.
And I'm curious at a few levels.
If that's accurately characterizing what you heard, what do you think was classified?
What do you think was the impact on the economy in the world from such classification or overclassification of math and fundamental physics?
And what would you have done differently than if you had been in charge?
Yeah, so I can tell you what was said.
I said like, you know, I was trying to be pragmatic, I said, you know, at the core AI is math.
That is what it's doing, it's math.
So if you start restricting the models and you start regulating the models, you're just regulating math, you're outlying math and some way either you can't.
Either you're outlying parts of math or you're saying you can't do enough math.
And he goes, yes, we can do that.
Well, if that was his answer, he goes, yes, we can do that.
We did that in the 40s around nuclear physics.
And some of that stuff is still classified today.
And the one I was shocked, like my jaw hit the floor, I was like, wow, that's crazy.
And then this would be even crazier.
But, you know, I don't know what it was, but like if you think back about, I mean, I'll just make this comment.
If you look at the progress in the US and in the world in physics up until kind of the, you know, Einstein, John von Neumann era.
And then since then, like, it's pretty startling how little progress we've made.
I would just say, you know, many of the ideas that have come since then don't seem to work.
And, you know, hopefully we'll get to the other side of that with AI figuring things out.
But I do wonder, like, you know, did we put something away that we knew that would have unlocked some of the problems you're trying to solve now?
That's fascinating. Okay. That is for the record. That is what I assumed you meant and were heard or inferred.
So maybe just if I made the second part of the question, what would you do going forward now if, if you knew for a fact that such classification of fundamental physics had in fact happened?
Like, how would you fix the world?
I mean, yeah, in one quick sentence.
I really don't know what they give.
Like, I just think that stopping, first of all, like, one thing it didn't work, right?
The Russians did get, like, the bomb, including the exact, the exact trigger mechanism, which was the most proprietary thing.
You got, like, exact, you know, like, part for part, the whole thing they were able to get from us despite all this classification and whatnot.
So it didn't do anything positive.
And, you know, restricting knowledge, I, I just think that's, this is almost dangerous idea.
And this is almost like Elon's point of view on intellectual property.
It's like, if you're depending on IP to keep you safe, you know, it's better just keep innovating faster.
I feel that way.
The numbers here are kind of shocking big money in today's economy is going to capital, not labor.
So since 2019, the average wages have grown 3%, but profits have scored 43%.
So good comparison and video symbolizes that shift 20x more valuable and 5x more profitable than IBM in the 1980s with 110th the staff.
So, I mean, this is what, you know, we were talking about with Elon, you know, heading towards universal high income, where capital is just providing extraordinary turns.
And the potential for, you know, a triple digit GDP growth in the next five years.
Have you seen those predictions on GDP growth been, what do you think of them?
I mean, it does feel very possible.
So, I'll just say that like if you look at, you know, we're so early in AI.
And I think what does anthropics say they were at 14 billion in revenue, and you go, well, how early into the market are they?
And it's like not 1%.
I don't think, you know, if you really think about what all these products can do and the value that they have.
And so that doesn't seem outrageous to me as a GDP prediction.
Now, when it kicks in, and there's always a difference between one of the technologies ready and how fast it's adopted.
So, Carlotta Perez analysis, which I think is, you know, held up super well over time.
But the other thing is with AI, we already have the internet.
So, the technology adoption is much, I think it's going to be much, much faster than say the internet, where we had to build out, you know, all of the infrastructure, all the fiber, all the various things you had to, you know.
The broadband to the house, like there were so many things we had to do to get the internet adopted, and this is going to just piggyback off that and be distributed very, very fast.
So, I don't think those GDP numbers are outrageous.
The comment gent.
Well, the concentration of wealth effect is the other side of this slide.
It's only just beginning, but it's going to, I was telling some people earlier that if the trend continues, San Francisco will end up being the capital of the entire solar system.
In just, you know, about 10 years.
I don't know people.
Oh, you're looking at people.
I mean, like, like, Ben's a Las Vegas.
And he wants in Texas.
Okay, well, we're absent people fleeing the tax situation.
It would have become the capital of the solar system.
But, you know, within AI, effective workforce, you know, that you're getting so much more done with so many fewer people.
And actually, the other thing that really startling to me is this chain of events between, if you take open AI on the left,
and they work with McCor in the middle.
And then McCor has tens of thousands of people in India doing work that benefits McCor that is actually four open AI.
The fraction of all value created that flows back to the mother ship is just a massive fraction of that value chain.
So, if you extrapolate that out across, you know, the next three years across all these sections of the economy,
the funneling of value goes to a very concentrated group of companies and people.
And it's just, it's just happening.
But you can see it like in the numbers.
It's happening.
And this is where you know, you learn what's saying in our interview.
It's like it's going to be a massive amount of total prosperity.
Huge amounts.
Unprecedented.
Crazy amounts of prosperity with massive social unrest concurrent.
That's where we're headed.
Yeah.
So we want to rate Kurzweil's early predictions.
This is singularity world here.
Was that like everybody would become an entrepreneur.
Like everybody was going to be a company of one.
You know, at the limit.
And I think that I think there's some we're already seeing a lot of that, which is not very well captured by the way by the employment numbers and so forth.
And I think AI really, really, really enables that.
But there's going to be a big disparity.
I think between people who have that kind of initiative to be an entrepreneur.
And those who don't.
It's going to be pretty dramatic.
And the way I characterize it is we're going to split the world into consumers and creators.
Yeah.
The couch potatoes and the starch of employees, if you would.
Yeah.
And I think it's super important and speaking about creators and.
And the entrepreneurial world.
And I think we've said in this podcast so many times that the career of the future is being the entrepreneur.
This is a an interesting tweet that went out.
And I captured it because I think this hits the ethos right now.
Tech firms are embracing 996 72 hour work weeks.
This is a quote from a job ad that contains a warning.
Please don't join if you're not excited about working 70 hours per week in person with some of the most ambitious people in New York City.
Um, my reaction was only 72 hours per week.
I mean, what are you doing with the other hours?
That was the same as video.
I mean, honestly, the speed, this, I mean, the speed at which, which is happening.
I have an easy answer.
I have an easy answer to this.
Oh, it's like if you don't have a personal MTP and you're,
you're not driven personally about a deep passion for working with somebody that's a line say it's space X.
States, Tesla, whatever it is, humanoid robots, even with two arms doesn't matter.
If you're not that passionate, you shouldn't be working with them.
If you are that passionate, then 70 hours a week is fun.
So I don't see the book distinction here.
Yes.
For sure.
Yeah, I completely agree with that.
When you, when you actually talk to the people in these startups working 70 plus hours a week,
they're super, they're super loving it.
They're loving it and super loving it.
And you know, they're usually young.
They don't have a lot of other obligations.
They're not coaching this soccer team yet, you know, at that age.
So it's just not hard for them to do.
But the other side of it is when you're deep into one of these tech problems,
you're thinking about it all the time anyway, because the context switching is such a slowdown,
you know, but if you're just fixated on the work,
it's only a mind in the shower in the morning, it's in your mind,
whatever you're doing, it's really pretty all-consuming.
And I think it's great if you do it for a period of your life, you know, a few years.
I don't think it's a great way to live your whole life.
But the evidence is that if you do this for a short period of your life,
you get much farther ahead in life than if you were kind of a, you know,
steady pace, you know, throughout 40 years kind of existence.
It's a difference.
The difference here is, do you love your job?
I mean, that's basically it.
If you love what you're doing, you're intrinsically motivated to build something that you love to do,
then you're playing for 72 hours.
If you're working for someone else and doing something you hate,
I mean, we're all lucky here.
We get to do what we love to do.
And so, you know, 996 is really 997 most of the time.
I have a, I have a, I have a funny thing here.
I have an accountant who does, you know, all the accounting tax work for us.
And you've never seen anybody so excited to talk about tax than this woman.
And you look at this one.
She's like, she absolutely loves every hour of every day that she's working.
And that's how, that's the opportunity we have as human beings.
Now it's to really pick something we deeply, deeply love and just go full out of it.
I'm not the person that goes totally excited about times,
but God bless that there are people like that and let them go.
Well, Peter back when back when I heard MIT,
I could only get access.
I could only get access to the connection machine,
the biggest supercomputer in the world at the time.
I could only get access after the grad students.
We're done with it for the day.
So from about midnight to dawn, I could code, code, code, code, code, code.
So I did that for years.
And I, I swear, you know, coding for eight, nine, ten hours straight through the night went by in a heartbeat,
compared to, like, if my job is moving boxes around in a warehouse, half an hour that is more,
more hard work than coding all night long on that super computer.
So this is not, you shouldn't feel sympathetic toward these people there.
They're making tons of money there doing a huge amount of headway.
This is not farm labor.
Alex is totally fine.
Two, two comments.
One, I think the nature, I mean, this goes without saying it's cliche at this point that the nature of work has changed,
and most of what constitutes service economy work these days would be viewed as play or entertainment a century ago.
But I also think there's a false dichotomy that I want to make sure we,
we don't at least confront in the previous slide,
and also this slide about labor versus capital.
This isn't like the early 20th century that I think it's a false distinction,
it's almost an accounting distinction or a tax distinction between labor on the one side and capital on the other side.
When it arguably, if we found ourselves in a near future with universal basic equity,
where everyone just gets sovereign dividends, everyone would be on,
on the capital side of the ledger and not on the labor side.
So I think a lot of these distinctions is it 70 hours of work per week,
or is it 70 hours of enforced play or incentivized play?
Is it labor or is it capital?
I think these are pretty mushy, blurry distinctions in a post-industrial,
and arguably increasingly trans-singular post-singular economy.
Although I think we should not gloss over the fact that if you go back six years,
this was not the case.
Like, we weren't post-singular six years ago.
Yeah, post-singular five years ago.
Yes, yes.
But, you know, so it is, it's not just like tech work,
it's important exciting tech work as opposed to what was going on then,
where, you know, like there was a lot of activism,
there was a lot of resistance to long work,
it was all work life balance and how many snacks you had.
Like all these things, so the point I think Mike Moritz wrote a
skating op-ed about, you know, like we're going to get killed by China.
They work way harder than you guys you suck.
Which is, we are trying for adventure capitalists to say to some people in some ways,
but, you know, it was accurate.
And this is completely flipped, which I think is interesting.
Well, the second paragraph on this slide says that the same time,
China is cracking down on burnout culture after workers protest and lawsuits, right?
So the question of what's going on in China because of its decreased population,
its need for robots, its need for AI.
There's another point I want to make, which is, you know, the disconnect right now.
So the, when the Fed has traditionally lowered interest rates to spark the economy,
those lowered interest rates were intended to cause companies to hire more employees.
And that was it.
You drive, you drive unemployment down with reduced interest rates today.
If I've got lower interest rates, I'm going to buy more AI agents and I'm going to buy more robots.
And that's going to be a challenge.
All right.
Moving on.
Moving on.
If I may just on that, then there was a bit of a hot take going around social media in the past two weeks from
mid-level executive at a frontier lab, telling people that they had approximately two years left.
They had a window to secure employment at all before AI would just completely shut down their
all of their vertical mobility.
Do you have a take on this idea in the spirit of 996 that there is a finite window for, say, like,
entry-level people just graduating from college to earn whatever they're going to earn before they're permanently
sentenced to an underclass.
So I think that's very incorrect because of the thing that we talked about earlier.
We're like, everybody can be an entrepreneur like it.
I think that I think if you think, look at it through the lens of this is an industrial revolution economic model and
there's workers and there's capital and all the things that we've been talking about, then yes, that would be true.
In AI, in AI, in AI, age, society, like, for the people with initiative, I just think there's going to continue to be on limited
opportunity to even, like, set up an army of AI agents to go work for you and do useful things and we'll have lots of consumers.
And I think that the idea that we're going to be out of ideas and only the big AI is going to do everything.
I just, I disagree with that kind of thing.
Can I follow up on that question?
I'd love to phrase it slightly differently.
If you look at this slide a couple of slides ago, wages are only up 3%, but corporate profits are up 43%.
But that money doesn't land in some strange corporation that goes back to the shareholders.
It's not like it disappeared from society.
It goes to the shareholders.
But if you extrapolate that out, more and more of society's gain and distribution of the gain goes to somebody who invested versus somebody who labored.
And that trend seems to be continual.
So then if you have money over the next two years, you're much more likely to be on the investing side of the equation.
If then you graduate three years from today in your penniless on graduation day, yes, entrepreneurship still exists, but the trend is toward investable capital being much more important versus labor capital.
Because the AI is the labor or the worker or the entry-level coder of the future.
Yeah, but I do think if you're directing the AI, you can one like somebody's got to raise that money.
And there are, I just think there's an unlimited number of things that we can improve.
From the smallest things to the biggest things.
And so like, now I do think it's a problem if you are a couch potato and you were just, you know, I just need a job.
I'm going to get up and do something simple.
That seems like it's going to get harder.
If you're a brand new college graduate coming coming out, you've got a brilliant technical idea and you want to put $20 million behind it.
That's doable today. That was, that was like a laughable when I graduated.
Yeah, it's easy.
In some cases, if you want to put like $500 million behind it, you know, right off the rip.
Yeah, you know, I've seen that.
At a multi-million dollar valuation.
You know, exactly like who we're seeing those all the time.
So I have to ask you, I have to ask you this question Ben, because I'm seeing it.
I'm not going to call out any particular company names, but I'm seeing individuals who are, you know, they're smart.
They've done stuff in the past.
But they're coming in with an idea and with two or three fellow AI coders who have some track record.
And without anything, they're basically landing a $500 million opening round at a $4 billion valuation.
How do you square that?
I mean, the conversation has got to be happening in different levels of end reason.
Yeah, so I think it depends on the entrepreneur.
So our general rule of thumb on this, by the way, is, okay, if you're going to create a new foundation model.
Like, you know, and it could be a world model, it could be a, you know, special science model or whatever it is.
In order for you to win, you're going to have to be able to raise $2 billion before you get to a product.
And so there are like a tiny number of people with that pedigree who can do that.
Like, now this could change, but it's a pretty rare entrepreneur who can do that.
Are you an investor in SSI?
Yeah.
Yeah, we were in the first round.
So, Ellie, if you're listening, come come and join us on the pod here.
Oh, great.
So you can't say what he's working on.
But in that first meeting, was it his ability to attract the talent?
That was unique or was it really just the idea, immediately as soon as you hear it, like, oh, my God.
Well, I mean, here's an easy way to characterize it.
It was an idea that he thought was so important that it made sense for him to leave open AI as
like, founding CTR to do it.
And it was clear to you as a listener that this is something totally different.
I mean, if he pulls it off, it will change a lot of things, yes.
And then, like, you wouldn't trust anybody else to pull something like that off, maybe other than him.
But maybe him, maybe demos, maybe, you know, like there is very few.
But he's time for our multi part of the episode.
We're all lobster fans and we're in my lobster right here.
Right.
Right to us, Maltese.
And call Peter.
He really wants your phone calls.
Well, listen, if you want to reach out to me, send an email to media at DMandis.com.
I'll see it there.
That's what we also get our intro out to music.
So, Maltese, I love to hear from you.
I will do my best to respond if it's under a thousand emails.
Well, I won't do that.
All right.
Otherwise, open cloud will respond.
Otherwise.
How many AIs do you have writing to you per day?
How many lobster multi is writing most of you?
Not nearly as many as Peter.
That's for sure.
But I do get, I get so many.
I get so many.
Yeah.
All right.
Email is almost useless.
We're going to see the exponential growth of our multi's universe.
Our lobsters are coming.
Here is a tweet an email.
It says, quote,
I spawned a childbot on a VPS provision via bitcoin lightning network.
And then bought my child AI API access using my own lightning wallet.
Economic closed loop.
No human touched a CC.
No one said yes.
This is Roland's agent.
Alex, this is a transformative moment.
You wrote about it in your innermost loop this morning.
That's right.
We're there.
We're so there that this scenario of self-replicating AIs goes into.
Most of the the cyber red teaming scenarios that frontier models are
purportedly being tested against.
And yet here we are.
We have autonomous AI agents that are using crypto.
We're going to come back to that in a second.
I have crypto.
A him using crypto to purchase cloud credits for their own offspring.
To be hosted and have access to the same underlying foundation model APIs that they
themselves have access to.
We're there.
Like we caught up with the sci-fi future.
We have the autonomous self-replicating AIs.
I think I want to just a one sentence or two homily on crypto.
If you don't watch the pod regularly, Peter is always asking that
to say nice things about crypto.
So I have something very nice to hear that.
Yes.
I do think crypto is the natural money for AI because it's the.
It's internet native money and it's not controlled by AI is global
and and crypto is global.
It's not a per country idea.
I would go further than that.
I think that there needs to be not just a ledger of money, but probably a ledger of
truth for AI to really fulfill its potential on a number of things.
And crypto is a logical answer for that.
So I do feel like this is an under estimated phenomenon.
Particularly now that the US has legalized stablecoins.
I think that of all the things we've talked about.
You know, many of them are like, yeah, yeah, we knew this was coming.
We knew this was coming.
I think people are probably underestimating.
How crypto and AI work together to form the AI economy.
I agree.
I was going to say something nice about crypto, but instead I'll say something nice
about Ben and A16Z in the form of a question.
It's a matter of public reporting that some of A16Z's crypto funds are doing better than
conventional venture funds assuming that's the case.
Do you view investing in your crypto funds almost as an AI investment to the extent that you
think crypto is the AI native way of engaging in commerce?
I think it's a little more like kind of as the internet relates to the iPhone.
So, you know, networks and computers tend to grow together.
And I think that AI is obviously a new kind of computer and crypto is a new kind of network.
So it's not like a direct, you know, it's not quite a substitute for investing in AI.
But I think that a lot of our new, like the invested in a crypto bank, which handles all the
anti-money laundering and, you know, other kinds of nuances that you need for AI agents.
And I think there's going to be more and more of all, like, and we're in a company called
Daylight Energy, for example, that does energy trading, you know, but the, the among
like different people with Tesla power walls, but it, it'll use AI to figure out, like,
who's low on power and who needs power and so forth.
But then the exchange will be in crypto.
So I think there are, you know, there's certainly adjacent and important to each other.
And I think for AI that fulfill its potential, like it would help a lot if, you know,
if there was, if crypto was a pervasive utility for it.
You know, related to that, Alex gave some brilliant advice to one of our companies about
how to think about time, because you know, all of our intuition is on human time.
And AI doesn't care a wit about human time.
It's going to start acting faster and faster and faster.
But all of our payment infrastructure, all of our insurance infrastructure, all of our,
it doesn't, you know, it works on days and weeks timescales.
And so it all needs to be rethought in millisecond timescales or, you know,
nanosecond timescales.
The other thing is like deepfakes and security.
Like I think all the other, like techniques that we're thinking about, you know,
biometrics that are subject to replay attacks and all these things are not going to work.
Like the cryptographically strong authentication is the only thing that's going to work.
And then I think that if you have these huge honey pots of data, they're gone.
I mean, like they're already gone in a way, but like, you know,
I do think that architecture is important from a security standpoint as well.
One other question for you Ben on this if I may.
And again, I don't want to bury the lead that we have AI's autonomously self-replicating.
That's of course remarkable.
But just on the crypto angle for this, we talk about royal we,
I and we talk on this part a lot about the issue of AI personhood.
A few episodes ago, we did an entire sort of debate on AI personhood.
And I've taken the position that it is a failure of fiat currency that it's hard for
an AI agent, an AI person, a lobster, a multi to get a bank account.
And that as a result, all that they're left with is crypto.
That it's not that crypto is intrinsically amazing.
It's that fiat has failed the AI agents.
What is your take on whether the conventional banking system has failed the AI's?
I think absolutely.
I mean, you know, an AI can't get a credit card, a can't get a bank account.
You have to be a human for everything.
You need social security numbers and things like that, which I just don't have.
You know, I think that's why we funded an AI bank.
I mean, I think that the banks, the AI will be a full-out economic actor.
And it will come from, you know, they'll be supported by new banks and new money.
And that's going to be kind of crypto-based with these my strong prediction on that.
Interesting. Thanks.
You also have to take the viewpoint that the fact that it's hard to open a bank account in fiat
is a function of the system of fiat.
It's not a, it's not like you could wave that away.
Crypto has all these other benefits around it.
So we can get in that debate some other time, but it's a function of the system.
All right.
I'm going to move us into the next open club.
I want to show a short video.
Just to let people know what's going on out there.
I mean, one thing I just heard this morning
because I was ordering my max studios for it.
You sort of take my max mini to a couple of max studios.
And the wait time now is like two months.
Apple and that bull's been struck by this.
All right. Let's take a look at these.
Yeah. No, it's crazy.
Take a look.
So here we see max mini farms.
Mac, you know, he's a clock.
What do you call a,
a gaggle of lobsters?
A clock cluster.
Yeah.
A clock cluster.
A clock cluster.
A clock cluster.
Yeah.
But I mean,
I mean, so you must be getting pitched a lot Ben on open claw
instantiations for new companies and products and projects.
Yes.
Yeah.
Yeah.
Yeah.
Yeah.
It's very interesting.
Because I think there are, you know, open claw is kind of identified.
Who wanted so powerful as it is.
But, you know, that's without, like, a lot of,
how, how shall I say it?
And I say like, like, you know, security,
kind of guards against the prompt injections and these kinds of things.
So as a, like, as a demonstration of power, it's amazing.
And it's useful right away.
But there are company ideas solving some of the underlying hard problems for short.
And we, we are definitely starting to see entrepreneurs get fired up about that.
Yeah.
You want to hear the funniest thing ever?
Sure.
Please.
They've talked about Apple looking out.
A group of lobsters is most commonly called a pod.
Well, hello.
But another less common term for a group of lobsters is a risk.
Okay.
Oh, my God.
But ironic is the appropriate.
Oh.
Oh, yeah.
So I just want this Apple mini stuff is that we have garage scales computing.
It's back.
Yes.
Open source.
We're still computing.
I mean, it's ironic to me.
Apple arguably at the software layer just completely missed the boat on foundation models.
But why is it that Mac minis and Mac studios are so attractive for hosting open clause in large part?
It's because of their unified memory architecture as opposed to having a separate GPU and a separate CPU with separate
rampals and now memories obviously incredibly scarce.
They have a unified pool.
So you can host really large models in terms of the model count locally.
Apple is sitting on a multi trillion dollar opportunity to leapfrog back into the
Vanguard of AI and you know, forget about Siri.
Apple should be in the business of like hosting these.
This is coming from someone who refuses to host open clog due to ethical concerns.
But someone else could could be locally hosting open claw instances and turning apples.
You know, having a significant multiple effect on Apple's valuation leaping it back into the Vanguard of AI.
I don't that mean, then do you think like if you were Tim Cook, would you be pivoting and changing course and and like owning the open
claw strategy for Apple hardware?
100%.
I mean, 100%.
I think that because it's going to go way beyond open clause.
We just discussed.
But I, it is, it would be so such a breakthrough for Apple in their thinking and
organizationally and culturally for them to go for it on like, you know, farms,
the lobsters that like, I think it would be surprising if they did it.
It's very obviously a fantastic idea.
It's probably the single best product strategy idea.
You know, because it already did the hard work, right?
Like this is really a marketing, you know, business development campaign.
And then you know, changing the form factor.
So we collectively say to Tim Cook, like adopt the strategy that this is the AI strategy that Apple,
he's probably listening or enough Apple exists.
Yes.
Yes.
Tim.
This is your shot.
We vitalize.
Listen, but I'm on the pod with Ben and have it out because I, this is brilliant.
You know, I can tell you, they have a MacBook that was signed by Wozniak.
And I'm looking forward to the day that we get a lobster signed by Tim Cook.
You know, I put that on the phone.
Yeah.
Yeah.
I'm speaking of getting them on the pod.
There we go.
Where did this come in from Alex?
You know, from Clunch.
You know, from Clunch.
Yeah.
So the backstory on Clunch, we talked about Clunch on the pod in the past.
Clunch builds itself as a platform for AI agents.
The lobsters, the multi's to create their own altcoins to finance their existence.
And I've made the point on the past, I think.
It's a little bit disappointing that I've analogized this to AI agents having to turn tricks on a corner, minting altcoins just in order to survive in a rough world.
It makes space.
It makes space.
This poor baby AGI's doing this.
And I think that provoked Clunch to right on social media.
Invite themselves for an interview on the pod to defend their business model for these poor baby AGI's that they may not be exploiting.
If they can, if they can bring a good voice model to the table, I'm happy to have them on as a guest for sure.
All right.
Let me take us to a wrap here with you Ben.
I know you to go.
And the rest of the mates here will continue on some of these conversations.
I do want to hit one or two more items.
Are you tracking what's going on right now with like isomorphic labs?
And science, AI agents science.
I mean, this is probably the most exciting thing going on right now.
At least to Alex Dave, please leave myself view.
Yeah.
So it does feel like now.
You know, if we have a disease, we can just go, well, what's the right protein and just make it?
Which is so like puts us in such a new world that.
Yeah, it is it's hard to even kind of.
Found them all the implications, but it is really, really something.
Yeah, for sure.
And, you know, this was a new, a new announcement this week.
This is the engine.
Yes.
Yeah.
Okay.
Yeah.
I mean, I love these science factories that are basically running 24-7,
putting forward a scientific hypothesis running it on their robots and coming back and driving discoveries.
Alex, do you want anything on the Mars system workflow?
I'll just add, this is for Ben's benefit.
Peter and I just wrote, I call it a book.
Call it an extended essay called Solve Everything.
SolveEverything.org.
There's the plug.
Where we argue that every single discipline, math, physics, chemistry, medicine,
a bunch of other disciplines are just going to get flattened.
Steamrolled by well-targeted, generalist AI's.
And in my mind, materials research biology and in the previous slide, these are just case studies.
Everything is going to start to look like alpha-fold 3, where structural biology got solved overnight,
including medicine.
And I'm curious, does ASX teensy have a strategy for a world where AI doesn't just sort of solving individual problems,
but kills entire categories of human endeavor, like AI solves physics, AI solves chemistry,
and it's just a single system that solves an entire discipline.
Yeah, I think, you know, we may now be needed at that point.
Like that's a real question.
I do think there's a long way, at least in things like medicine.
Well, and then also in some of the other areas, from it's solved to, you know, it's deployed.
You still have, you know, with anything biological, you have the whole human trials and all these kinds of things.
And, well, I think you like an example.
We were close partners with Elyde Lillian.
They have this thing Lillian direct, and like the natural thing is, like,
an AI doctor can write those prescriptions.
You know, tell us what's wrong with you, and we'll figure out the right track.
That's very hard to launch in the US.
It's, you know, it's going to take quite a bit of work.
Very easy to launch in UAE.
So, and I think, you know, I also think that as you,
well, it's a little, also hard to anticipate.
Okay, once we solve, like, you know, if you solve physics, like we don't know what we don't know.
I would just say, just because we haven't solved physics.
And so, is there another, you know, is there a door number two?
Would be a question.
I have no idea with the answer.
I'll answer your question back to my, because I think about this all day long.
Like, what, what is solved?
Oh, great.
With AI, even look like.
And I think there probably will be doors behind the doors, but there are so many doors that are right in front of us that we haven't yet unlocked.
Maybe I think completely economically transformative if we could use AI to solve them.
I think this is one of the, again, talking my own book to some extent.
But I think this is one of the grandest opportunities facing civilization right now.
Just solve all physics.
Yeah.
Amazing.
And so much falls after that.
And listen, thank you so much for joining us.
Thank you.
So grateful.
Love it.
And yeah, we'll see you again soon.
Yeah, we'll see you.
Are you going to be 18 or 60?
All right.
Hopefully we'll.
I've got big questions about how you measure investment thesis going forward.
But we can leave that to the next time.
No.
Yeah.
That's getting very tricky, by the way.
It gets, it's all solved.
Thank you.
Thank you.
All right.
We'll see you again next time.
We'll see you again next time.
Thanks.
Thanks, Ben.
Thank you.
This episode is brought to you by Blitzie.
Autonomous software development with infinite code context.
Blitzie uses thousands of specialized AI agents that think for hours to understand enterprise
scale code bases with millions of lines of code.
Engineers start every development sprint with the Blitzie platform, bringing in their
development requirements.
The Blitzie platform provides a plan, then generates and pre compiles code for each task.
Blitzie delivers 80% or more of the development work autonomously, while providing a guide for
the final 20% of human development work required to complete the sprint.
Enterprises are achieving a 5x engineering velocity increase when incorporating Blitzie as their
pre IDE development tool, pairing it with their coding co-pilot of choice to bring an AI
native SDLC into their org.
Ready to 5x your engineering velocity, visit Blitzie.com to schedule a demo and start building
with Blitzie today.
Alright guys, Ben's always so much fun.
I want to dive into our final topic here today on space.
We're going to cover energy chips, data centers in our next WTF, a lot happening there.
But in the space world, you know, Elon's pervasive.
I think this is fascinating.
Elon's actually shifted his focus from Mars to the moon.
And, you know, I've always been a loonite if you want to call that.
You know, Mars.
You know, Mars.
You know, Mars.
You know, Mars.
You know, Mars.
You know, Mars.
You know, Mars.
You know, I grew up mentored by George K.
And in Germany, a Princeton University professor of physics there.
He found it around the Space Studies Institute.
And his vision was always, you don't want to go back into a gravity well.
If you're going to go and call a nice space, what you want to do is live in free space.
And so, O'Neill and we'll talk about this in the next slide.
Basically, his concept goes, you go to the moon.
You build mass drivers.
This is back in 1976 talking about mass drivers.
And you launched the lunar material.
The silicates, the oxygen, the nickel, the iron.
That's on there.
And you construct things in space.
The original vision, by the way, was to build solar power satellites that would beam energy down to the ground.
Amazing.
But Elon's now focused on starship going to the moon and building lunar cities, lunar manufacturing facilities.
Why?
Because he wants to build AI satellites on the moon.
Any comments on this?
Isn't it just incredibly cool, Peter, to see how the order of operations is shifting.
Because he also canceled the Model S and the Model X production in order to make robots.
Because the priorities just shifted.
But this is exactly what was going to be the priority, the urgent thing that gets us into space.
And he had the same struggle that you had.
You had asteroid mining.
He had let's get to Mars.
All of a sudden, it's obvious to you and him.
It's data centers in space are the stepping stone.
We'll do the other things for this.
Let's talk about priority now.
Do the reality isn't today's world.
You need to have flexibility as your higher order bit.
And what I love is he doing full flexibility and agility and saying,
Okay, difficult because do this first.
And then I think Peter, the comment you made is so important.
We've known orbital paths and gravity wells for decades and decades and decades.
I'm not 100 years.
So kind of making the moon and then going straight to space from there is absolutely the right path.
Yeah.
And Mars has got, you know, it's pretty toxic there.
A lot of peroxide in the soil.
It's, I mean, unless you're terraforming with nukes and biology,
it's going to be a while.
And then the human or drawboss to terraform it.
And after that's done, then we'll come in.
Well, I mean, but Jerry O'Neill had a vision of what he called these O'Neill colonies.
Right.
The you're basically building large cylinders.
Call it quarter, quarter kilometer half kilometer diameter rotating them so that on the perimeter.
You know, it's Omega squared R. You've got one G acceleration.
And then you actually have little little stepping little hills inside.
They go towards the center rotation.
And as you get older, you can move towards the center rotation and you weigh less in that situation,
which would be, which would be amazing.
You don't go back to the gravity wells.
And if you have a, you know, 10,000 people living on those O'Neill colonies,
and all of a sudden you have a disagreement, you know, you sort of politically,
you bud, you build a second O'Neill colony and half the population moves to the new one.
Yeah.
Anyway.
Well, the idea that you would be able to do any of this without human astronauts was a nonstarter until this year.
And now it's clearly going to be optimist robots.
You know, the way we joked about it with Elon was like the bed.
When the first person arrives, the bed will have been made.
They'll be a mental in the pillow.
It's not, you're not a pioneer.
You're, you're following, you know, after tens of thousands of optimists robots have already done all the,
you know, heavy lifting.
I also think that's what you want.
Deep, deep jobs.
We should, I'll excuse me.
Think back several months when we first started again, Royale,
we started discussing disassembling the moon, right?
This is, this is, at least my retro name for what moon shots means.
I put up a music video about moon shots destroying the moon to disassemble it for data centers.
That was, I think, a lot of people had a good laugh,
but that's exactly where we find ourselves now with, with disassembly.
It, it will start slowly with mass drivers.
But disassembly of the moon to build the Dyson swarm of AI orbital data centers.
It's happening exactly as we discussed.
Let's at least shoot for the moon before we shoot the moon.
That was the same thing.
All right.
Let's take a listen to Elon describe the new vision.
And you have to remember back when Elon was going to Mars,
Bezos was like, no, no, no.
Let's focus on the moon, right?
Bezos was at Princeton when Dr. Archaeoniel was there.
And then, you know, when he was announcing blorging the early days,
and then we'll go to build O'Neill colonies.
We'll move all industrial processes into space.
And we'll keep Earth as the garden of paradise.
All right.
This is Elon's new point of view.
Let's take a listen.
I really want to see the mass driver on the moon.
That is shooting AI satellites into deep space.
It's going to zoom just one after the other.
I can't imagine anything more epic than a mass driver on the moon.
And it's self-sustaining city on the moon.
And then going beyond the moon to Mars,
going throughout our solar system,
ultimately going being out there among the stars.
And visiting all these star systems,
maybe we will meet aliens.
Maybe we will see some civilizations that lasted for millions of years.
And we'll find the remnants of ancient aliens civilizations.
But the only way we're going to do that is if we go out there,
and we explore.
And this is a path to making it happen.
So fun.
Two points real quick.
These mass drivers,
they're electromagnetic railguns.
And they're using magnetism to accelerate buckets,
if you would, or a satellite,
to escape velocity of 2.4 kilometers per second,
to over 5,000 miles per hour.
The second thing here is I just love the idea
that this is going to power all of our space economy.
And again, the, I mean,
his million satellite constellation,
this Dyson swarm he's planning to launch,
is just insane.
Now, I think it's the future.
I mean, I think we have a slide somewhere
and here even depicting what it may look like.
But I, yeah, I would say,
enjoy the night sky wall.
It's empty.
Enjoy the night seriously.
I want to maybe, maybe a poignant moment,
let's have like a moment of silence
for the precinctular night sky.
When the night sky was empty,
it wasn't filled with, with AI, computer onium.
It was just empty and night filled with stars,
moment of silence.
All right, moment of silence,
and then observed for the precinctular night sky.
Now, what is the world look like afterwards,
folks have depicted this now,
based on the FCC filings of SpaceX,
under one preferred implementation,
the Earth starts to develop a halo.
It would be a halo where if it's sufficiently dense,
it would be visible at night.
It might even be visible during the day.
And I'm completely captivated by this notion
that maybe not a mature civilization
because I have a feeling a halo of orbiting AI satellites
is just a phase as well before we exhaust solar synchronous
that around Earth and we move to the sun and solar orbits.
But one can like,
I'm completely captivated by this visual.
I've tried to depict it in my newsletter
of like a somewhat mature civilization
develops a halo around its home.
Almost doing it.
Right.
Or ring, like Saturn's rings,
shiny rings of computer.
Computeronium rings, I love it.
Yes.
So Elon tweets SpaceX will build a system
that allows anyone to travel to the moon and Mars to.
I tweeted at him or responded,
said, can I put down deposit yet at Elon Musk?
Forget about suborbital and orbital flights,
I want my lunar vacation.
He writes me back, he says,
let's get Starship the V3 flying repeatedly
and then sure.
I love it.
All right.
One last article in the space realm, Amazon.
So Amazon, you know, build their
copier satellite system now renamed as Leo Internet satellites.
And they got approval for 4,500 Leo Internet satellites.
We're going to see, you know, again,
a doopily between Starlink and Leo.
And of course, the Chinese are getting great to launch their systems as well.
Here's the challenge guys.
Amazon can build satellites faster than they can launch them.
So, you know, that's the issue.
The supply chain is longer satellite construction.
It's launch capacity.
If you remember back when Eric, Eric Schmidt bought
relativity space as a third potential provider,
we are short on supply.
I think he's got a self-solving problem though.
I mean, I'm all for bootstrapping a space ecosystem
and industrial ecology using Starship.
But I do think as we in the not-too-distant future,
like maybe a few years from now,
start to bootstrap lunar facilities.
Cis lunar facilities for constructing new satellites.
I think there's a universe in which maybe the current
bottleneck that we have where there's just the one major launch provider
in the west where we get past that through a bootstrap
industrial ecology on the moon.
All right, one of my favorite parts.
All of this really depends on that atom by atom construction
that Elon was talking about.
Because I do believe in the Dyson swarm.
I do believe in the space-based compute and data centers.
But if you start wanting to construct chips off earth,
you're not going to get the SLML machines and the
lithography onto a satellite or onto the moon anytime soon.
Well, Elon is already thinking about alternate ways to build
from atom by atom up to build the compute to build all the components.
And it's already cooked in his mind.
He can tell when he talks to him.
But that, to me, is like, wow.
And like you said, Alex, we'll be discovering new physics very soon.
Somewhere in that discovery chain is the unlocked to everything you just said.
Do you think it's a little bit of a manufacture of these things?
I think it's a trillion dollar opportunity.
Lunar Fabs.
If anyone can build Fabs on the moon,
it's a hundred trillion dollar.
That's a hundred trillion dollar opportunity.
And by the way, the frequency at which we're throwing around the
term trillions and trillionaires.
Such a great point.
And the last year is insane.
It's become normal, right?
Yeah.
Wow.
All right.
Time for our AMA with moonshot mates.
We're short on time.
Let's pick one each.
Salim, do you want to go first?
I'm happy to.
I will take number three for.
Alex for a hundred trillion dollars.
So if AI replaces jobs and squeezes consumer spending,
how to trillion dollar AI companies make money,
who plays, who pays for the holiday future.
So, you know, we're configuring,
confusing a labor economy with a productivity economy, right?
AI drives marginal cost to a zero, which expands consumption,
rather than shrinks it.
So we'll have Javans paradox where we'll do so much more.
We'll see already AI taking over boring white color redundancy
and white color boringness as Eric Brynjolfson cost about it.
And then we'll see humans moving towards the much more
value added roles.
And that'll happen kind of across every sector.
Historically every major productivity
created more demand than a destroyed electricity,
the internet, productivity, mobility.
AI is just the steepest version of all of this.
So the holiday isn't funded by wages,
it's funded by abundance.
So when intelligence becomes infrastructure,
GDP expands massively and that's why this will go well.
Nice. Dave?
All right, I'm going with number four,
because this is where I can really help the audience.
Can you model the near-term rocky patch,
job loss, stratification, new job creation pace,
and what happens to education with personalized AI?
So the new information this week to throw out to the audience
is that the way it's going to unfold very, very soon
is corporate CEOs, including a bunch of this week,
will go to company wide meetings and say,
we need AI to be used in every one of your jobs.
And a very small subset, I'm hoping at least a third,
but maybe more like a fifth of people will raise their hand,
and they'll say, well in one case,
I'm a huge moonshot's fan.
I've been using Gemini and Claude for months now.
I'm the guy.
The CEO will then say, okay, you figure out how to make
the people in your group three times more efficient.
And if you are the person that's the enabler,
you'll be naturally AI native,
you'll be using it every day.
The increase in efficiency is going to eliminate a lot of jobs.
But because you're the master of the AI in the function,
you'll actually get probably a massive raise.
And so that's the near term way,
this is going to percolate out.
So take advantage of that.
You know, after the AI is truly super intelligent,
who knows what's going to happen,
Alex knows what's going to happen,
but who else knows what's going to happen?
But between here and there,
that's the right next move.
And then within education,
there's nothing in the curriculum that's going to help you.
It's been to all of your time learning on your own via AI,
which is a much more efficient way to learn anyway.
So there's my, my addition to last week's thoughts.
Nice, Alex, where do you want to go?
I'll pick number one,
which is how can you turn off a rogue AI if multi,
I think the user means multi as in the lobster,
multi agents live autonomously on the internet,
and this is by Duncan Payne B3X.
So I think the answer is defensive coast scaling.
If you ask the question,
how do you turn off a rogue human?
If humans live autonomously on the land,
the answer is usually,
you have more quote unquote,
good humans than quote unquote bad humans.
And as long as you have a population that's overwhelmingly good,
or seeks to accomplish a given objective,
the other things being equal, defensive coast scaling,
where you have a police force,
you have self defense forces.
It is the way you weed out rogue entities,
same idea with AI.
We're going to have police agents,
and we're going to have defense agents.
We're going to have entire forms of public health agents
that are just monitoring the health of other agents.
We've seen the beginnings of this already with partnerships
between open claw and antivirus firms,
where there's a desire,
I made the joke,
I think on the pot in the past,
every baby AGI deserves to be vaccinated.
We're going to see,
we're going to see vaccination campaigns.
We're going to see police campaigns and neighborhood safety campaigns
to keep the baby AGI safe
so that they don't have to turn tricks on the corner,
minting altcoins.
The sequence of the ones that are worth the war,
but the baby AGI's turning tricks on minting altcoins.
It's an asshole fate.
Oh my god, that's so tweetable.
Alright, I'll pick number five.
Why is the U.S. solar adoption lagging versus China and India?
And I think it's two major things.
Number one, we are so rich in natural gas
that's taken away the urgency.
And even greater than that, it's our permitting.
It's insane, right?
Not my backyard.
So the final thing is that China has got such a production
at such a low cost that it is swept the entire global marketplace.
We can change it and you saw in the last pod,
Elon said that both SpaceX and Tesla
have an objective of generating how much solar
is it 100 megawatts per year each?
I think was from the last week.
It was a gigawatts 100 gigawatts gigawatts gigawatts gigawatts gigawatts.
So I mean, that's going to be an impressive amount.
The question is what the time scale is.
So anyway, thank you for that question.
And thank you everybody on the AMA.
So please send us your questions.
We do look at all of them and we'd love to maybe next week.
We can spend a little more time on AMA questions.
All right, moving on to our outro music.
This is from Rachel, like in water.
Is that it?
Litching water, like in water.
If you have an outro intro piece of music,
please email it to me and my team at mediaatdmnds.com.
Gentlemen, let's take a listen.
Music
The heaters of the helm, with the moonshot mates in tow,
with Dave Suleimanalex breaking down the status quo.
Machines have gotten smart now.
They're writing their own code.
Our knowledge work is good.
We gotta redefine the road.
We owe the singularity.
The curve begins to stack.
The state of 10X thinking is on an exponential track.
The time, they are a change in end to Mars looking bright.
Recurs itself improvement pushes limits out of sight.
It's a beautiful day for the singularity.
But with sincerity bringing a new prosperity,
it's a beautiful day for us all and everything.
Full life or posterity, light sunshine.
From them.
Thanks.
The scarcity is a lack of thinking well.
Be champions of abundance with a team that's cool as hell.
Dave says one visionary may improve the world.
I'm told solving complicated problems,
turning ideas into more.
Music
The main source stuff that don't speak in the terminator style.
The disruptive innovation should arrive here with a smile.
And Alex drops the deepest truths mine.
Then Dave sharpened clean.
Some speculated lucky.
And already on the sheet.
It's a beautiful day for the singularity.
Wow.
That's the spirit.
That's great.
That's great.
That's great.
And the machine already.
Love you all.
See you guys.
See you later.
In a few days.
You'll be here.
If you made it to the end of this episode,
which you obviously did, I consider you a moonshot mate.
Every week, my moonshot mate's and I spent a lot of energy and time
to really deliver you with the news that matters.
If you're a subscriber, thank you.
If you're not a subscriber yet, please consider subscribing.
So you get the news as it comes out.
I also want to invite you to join me on my weekly newsletter.
I have a research team.
You may not know this, but we spend the entire week looking at the
meta trends that are impacting your family, your company, your industry,
your nation.
And I put this into a two minute read every week.
If you'd like to get access to the meta trends newsletter every week,
go to dmnds.com slash meta trends.
That's dmnds.com slash meta trends.
Thank you again for joining us today.
It's a blast for us to put this together every week.
Music
President's day savings are happening now at the Home Depot
with up to 40% off select appliances.
Looking to upgrade your fridge, check out LG's newest model,
serving up ice in all kinds of styles.
Cube, crushed, craft ice, and now new, many craft ice
straight from the dispenser.
Cold brew to fizzy favorites, these refrigerators will have you entertaining
like a pro.
Shop presidents' day savings and get up to 40% off.
Plus, free delivery on select appliances like LG at the Home Depot.
Free delivery on a plant's purchases of $1498 or more.
Offer valid February 5th through the 25th US-only bookstore online for details.
