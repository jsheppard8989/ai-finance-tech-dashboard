When do we see a billion dollar revenue company being run by an AI CEO?
I think it's pretty likely that they're already as such a company right now.
U.S. jobs disappear at the fastest rate of this January since the great recession.
This is not really a recession. It's literally tasks being evaporated in front of our eyes.
This shows us marks was wrong. We knew that anyway.
We have the capitalists who are being first in line to be replaced by the automation.
For me, this is the social contract, literally by little disappearing pixelating away.
Alex and I are going to be unveiling a paper and working on for some months.
It's called Soled Everything. How do we get to abundance by 2035?
The next 18 months to two years are going to set the rules down to the next century.
We're about to have this conversation.
The paper slash book is nine chapters. Are you ready to jump in?
No one expects the singularity, Peter. I'm ready.
Now that's the moon shot, ladies and gentlemen.
Everybody, welcome to moon shots. Another episode of WTF just happened in tech.
I'm here with my incredible moon shot mates. D.B.2, Salim, AWG.
Guys, it is just accelerating.
In fact, this is the second WTF episode. We're recording this week just because the news is just incessant.
We're going to have this podcast today in two parts.
First, when we covering the news that's breaking a lot of it, really important news.
The second part, Alex and I are going to be unveiling a paper.
We're working on for some months. It's called Soled Everything.
How do we get to abundance by 2035?
This is the equivalent of the paper released to situational awareness in AI 2027.
And this is our view of where things are going.
So in second half, get ready for this excited to present it.
I chose the brilliance of AWG.
I'm in Sun Valley at the moment, speaking at 20 Robbins Platinum Finance event about AI and longevity.
Dave, you're back at MIT, Salim. Where are you pal?
I'm home in New York, waiting for the warm weather to hit and get us above zero for once.
Why ever left India?
No, why you left Florida is the great answer.
Alex looks like you're in your normal setting.
The audiences convinced that I live in VR or maybe a hotel and you wouldn't.
You probably would believe the YouTube comments on the flowers and the lamp and their purported in variability.
And I have taken that point out that the workings have changed actually.
The workings have changed, but I'm getting flower keeping advice in the YouTube comments.
At this point, people telling me to put ice in the orchids.
And I have to say I'm having so much fun with Cloudbot.
The lobsters have begun to become part of my life inside and out.
So I'm bringing them into the conversation here.
I got jealous Dave of the lobsters in your view.
I'm holding the lobsters back for now.
We're having a trouble small.
It's actually more I hit some of them down.
It is a troubles moment. You're absolutely right.
Hopefully it's not the trouble with the lobsters.
These troubles are economically productive.
Okay. Well, these are and they're so much fun.
I can't wait to express the level of collaboration I'm having with my Cloudbot, which I've named.
Skippy, if anybody knows where the name Skippy came from, put it in the comments.
It's my favorite AI from science fiction.
All right. This is the number one podcast in AI and exponential tech.
Getting you future ready, getting you ready for the supersonic tsunami heading our way.
And with that, let's jump into the news.
First off, top AI news.
I love this article.
This came out from Forbes.
Sam is the cover child cover boy for Forbes this week.
And the question is will chat GPT become the CEO of OpenAI.
So this is what Sam said.
You know, pretty simple. He has a succession plan.
He said he doesn't want to be the CEO of a public company.
And honestly, being the CEO of a public company is a pain in the neck.
So taking it further says, you know, if the goal for artificial intelligence is to become so advanced
that it can run companies.
He asked, then why not run OpenAI?
I would never stand in the way of that.
He says, I should be the most willing to do that.
I find that fascinating.
You know, when will we see an AI actually running a significant economic engine like this?
Davis.
This is no joke, actually, because this is board meeting week for me.
So I have back to back.
Today the cash cow from Dartmouth and tomorrow the two trillion dollar asset manager.
Then the next day the public company ever goes all back to back.
And in every one of those meetings, this is the topic.
Not replacing the CEO, but all of our plans are now in written form that we can digest with AI.
So we're trying to track every single movement within every company in documents digestible by AI.
And then if you ask the CEO, well, what do you do?
It's mostly set course and set strategy, which is a very small fraction of total time.
What else do you do?
What's the other 90% of time go into?
And how much of that can be done by AI today?
And the answer is a lot, which is great, because then the CEO is unleashed to be even more effective at setting strategy and also promoting the strategy.
So I don't think that part's going away anytime soon, but the other 90% is really just, you know,
inbound information getting routed into into the organization to do these specific tasks, which is outbound.
Is documents in documents out now?
So we're really here now for this.
So again, I've been talking about this forever.
What are we going to have AI board numbers, AI executive teams, and eventually AI CEOs thoughts?
Yeah, we're seeing this shift from, is it from a tool to being a governance actor, right?
We already have an AI minister in Albania.
And initially, these are kind of like toy things, but in reality, this is very powerful stuff,
because any AI scanning can be scanning millions of documents at a company in real time,
has a much better sense of what's going on in the company than any human being could possibly do, right?
A typical loop in a big company's, the senior management sets some direction or policy cascades down,
the coal face the people do it.
It takes a long time to get down there.
You have Chinese whisperers by the time it's down there, doing some activity that nobody at the top even knows about.
And then they start doing stuff, report back up to the top.
You've got another set of Chinese whisperers.
And by the time data gets to the top, it's diluted so much.
And you lose all the intelligence in the middle, right?
And so AI is going to come through and break through radical, uh,
critical opportunities to do this.
And I think what will happen is we'll see a pure AI organization at some point soon,
but they won't look efficient to look literally alien.
And that's fine.
I think that is one of these where you can't wait for it to happen.
And then you can't compete against that.
Right?
Because it's time dilation.
I think that, you know, I asked Alex for some help with the strategy of a big company earlier this week.
And one of points he made in his answer, which was brilliant, of course.
One of the points he made in his answer was time dilation.
You know, if you look at banks and insurance companies and, you know,
practically anything, it doesn't change strategy more than once a decade.
You know, or once every millennium.
Uh, now in the age of AGI, the course corrections are going to be, you know,
it'll go from decades to years to months to weeks to minutes.
All of a sudden.
All of a sudden.
A couple of years.
If we have a, we have a whole section in the first, you have so book called Death to the Five Your Plan.
Right?
Because today by the time you've finished your five your plan, it's out of date.
Then you spend all your time maintaining the plan.
Exactly.
Exactly.
So the amount of information that you need to assimilate to do those course corrections is beyond human.
There's just so much going on.
If you read Alex's daily feed, you know, the amount of change going on.
If you compare it day over day, you can see the expansion of the rate.
And so it's just so much happening that it's beyond human assimilation at some point.
So you have to have an AICEO to assimilate it and even suggest the course corrections.
And Dave, you said it over and over again, right?
The CEO in part is to understand what his or her employees are doing.
And if they're making the most efficient use of their time and the resources.
And it's all knowable.
But just not by the human right now.
But the AI can be giving you an understanding of this person's operating at 50% of capacity.
Or this person's not making the make best use of the others.
That's not management.
The AI's will do very well.
I think where you have the C suite in the CEO.
They'll be holding the purpose.
Hence the MTP.
Yes.
So that's they need to hold direction.
And what problems the company organization is actually trying to solve.
Yeah.
So there's two sides of this.
One of them is outbound strategy.
You know, simulate all the data from the world.
The other is inbound.
What are all my people doing?
And why?
And the others are the kind of the two sides of being a CEO.
And Peter just brought up that inbound side.
Which is the name you emphasized.
And I think on that front.
You know, this is complan season right beginning of the calendar year.
I'm tying everybody's CEO complan to data gathering this quarter.
So that we have everything that's happening in the organization now.
You know, Peter you've been saying privacy is dead for a long time.
It's everything is noable all of a sudden.
And there's a whole bunch of mechanisms for that.
I won't even get into it because this will go too long.
But if you're a CEO or a senior manager in any company right now,
really focus Q1 on how do I grab absolutely granular information
on what everybody's doing so that I can start to feed it to the AI to get
its opinion on whether these are the good.
That's tough this time.
Stuff is speeding up Alex.
What do you think?
I mean, to put a sort of concrete objective on this,
when do we see a billion dollar revenue company,
not not valuation because valuation skyrockets through the roof
when you pulled two or three smart people together.
But a billion dollar revenue company being run by an AI CEO,
what's the timeline for that Alex and what's your thoughts on these?
Probably several months ago.
Several months.
You think there's a billion dollar revenue company being run by an AI right now?
I think it's very likely that there is a billion dollar run rate company
being run by an AI.
Now you said run by I think there's probably a human CEO.
They're for legal purposes and meeting.
Meet puppet purposes.
Meet puppet purposes.
But I think it's pretty likely that there already is such a company right now.
And by the way, if you know of one, please put it in the comments.
We'd love to hear about it and see it.
If you want to blow the whistle on meet puppetry,
you can blow it to Peter.
Yeah.
All right.
Anyway, I love this idea.
You know, it's eating your own dog food.
If in fact, you know, if in fact Elon believes that we're going to have the smartest AI
is coming out of XAI.
And if opening AI believes the same for it's, you know,
cheap jet GPT6, whatever comes next, it should be the CEO.
I also think if I may marks was wrong.
This shows us marks was wrong.
We knew that anyway.
But this is another case in point.
Look at what's happening.
The story that unfolds here is we have the capitalists who are being
first in line to be replaced by the automation.
It's not the workers.
We see booming jobs for electricians and HVAC engineers.
Their salaries are booming.
And yet CEOs are first up to be replaced.
So if anything, I would sort of take marks off the shelf
if it was on the shelf at all.
Replace it with more of X paradox, which is again,
this paradox that tasks that are hard for humans in easy for
humans are respectively replaced by easy for machines.
Hard for machines.
Machines are able to do complex calculations,
solve math.
It's pretty hard for humans.
There looks like it's going to be easier for the machines to
automate away CEO labor, which is sufficiently hard for humans
that it's well compensated and relatively scarce
commodity to find high quality CEOs.
And yet it'll take a few more years for the machines to do an amazing
job at unskilled manual labor.
I, for one, cannot wait till the AI CEO overlords take over
the world.
I wish I could have an AI CEO taking over and running my company
instead of having to do it myself.
It's a pain in the ass.
It's hard to do that.
It's harder than running, pal.
Yeah.
You have to feed it properly, et cetera.
It'll happen.
But I just can't wait for the speed of that.
Exactly.
It's super fun the way we're going back to Claude
but is it the fact or handle instead of open clubs?
Lobsters with the mascots of the singularity.
Lobsters are here to stay.
Hey, everybody.
You may not know this, but I've been an incredible research team.
And every week myself, my research team study the meta trends that are impacting
the world.
Topics like computation sensors, networks, AI robotics, 3D
printing synthetic biology.
And these meta trend reports I put out once a week,
enabling you to see the future 10 years ahead of anybody else.
If you'd like to get access to the meta trends newsletter every week,
go to DMandis.com slash meta trends.
That's DMandis.com slash meta trends.
All right, staying with our open AI team.
This is incredible.
This is about feeling the speed of the singularity.
Open AI achieves 70% time reduction between models.
So open AI released their release sequence has gone from 97 days to 29 days
on a release cycle.
Andthropic with their Opus 40 and Opus 40.
6 took about 73 to 75 days.
So the concept here in Alex, I think you or Dave mentioned it last time.
We're effectively heading towards a continuous deployment,
like it's continuously being improved.
And whether you call it 0.6, 0.7, 0.8,
this is continuous improvement.
Alex thoughts on this.
I do think we're moving toward daily and then hourly and then
minitly releases certainly.
I also want to take a step back and try to understand why this is happening.
The obvious factor, it should be obvious is competition.
There's leapfrogging that's intensifying between all the frontier labs.
So some quantum of why we're reducing by 66% or so 70%.
The release cadence is just due to intensifying competition.
That's the boring explanation.
I think more interesting explanation is that the technologies behind the
releases themselves have evolved.
So historically when we were dealing with annual releases,
that was a world in era of pre-training.
When if you want to new model, you have to do different architecture.
And you have to pre-traine off of a larger corpus with more compute.
Those were the days of the original Chinchilla scaling or
Kaplan scaling before that.
And that was a much slower world because if you wanted to new release,
you have to start all over again.
Then we moved with a one slash strawberry, which was sort of the herald for
reason.
I was eight, six times two years ago.
Oh, my goodness.
Yeah, there's like so many singularities ago.
So we moved to the era of reasoning models when it was possible
through a process that used to be called iterated amplification and distillation
to take a pre-trained base model, a baseline model,
and then, cyclically, generated bunch of training data and distill from that to a child
model, repeat the process over and over again.
And that post-training revolution for reasoning models was much faster.
Like it's much faster to post-trained a model off of a corpus of synthetic data
and so release cycles contracted.
And I think now we're on the edge, probably slightly past the edge at this point,
of a new era, call it the recursive self-improvement era,
where the models are starting to rewrite their own code.
It's not just a matter of a parent or teacher model,
generating synthetic training data that's used for a child distilley model.
It's literally the parent is writing the code for the child.
And that can be done even more quickly than just post-training.
And I think it's just going to get faster and faster until it's a continuum.
Yeah, it's going to accelerate like crazy,
but also we're in a window of time, a very narrow window of time right now,
where the very best technology is available to you.
The Claude gives you their absolute best 4.6 and open AI does and Gemini does.
I would not count on that surviving post-the-self-improvement era.
Right now also the Chinese open source models are pretty much right on par with the best of the best.
They're slipping a little bit, but I think the window of opportunity to take advantage of that
and build something out of it is right here right now.
I really doubt two years from now that the best AI is going to be just log and angle here.
Here you can have free access to it.
And what'll happen is it'll be deprived of it with the excuse being security and safety.
Interesting.
True.
I mean it's pretty hard to deny.
But you have a window of opportunity right now to be on the very cutting edge.
If you don't take advantage of it now and get somewhere with it right now,
I wouldn't count on that existing.
So the models are going to go dark, right?
It's going to be, it's the secret sauce is going to be kept internal to benefit those companies
as they go into an all-out battle.
Well, even today, if you talk to no one brown over to an AI, he's working on the next generation internally.
But it's only like three months in the future that he has access to.
But three months in the future in the era of self-improvement is massively different intelligence level.
The definition of three months of AI development,
you know, two years ago, when you're going today, that's the point of the slide, I guess.
It's like three months, it's like a lifetime of difference in capability that they're using internal labor.
It's what's, you know, available on the outside world.
So you got to expect that this is, it's now we're never to react, basically.
And people are still hugely underreacting to the importance of what's happening right now.
Insane.
Selim.
I've got to kind of like the crazy antithesis of this.
We're working with a large monster European corporation.
And we showed them something that can give them massive impact straight to the bottom line.
And the response was, oh, this is fantastic.
Let's bring this to the planning meeting in October.
Right?
And you're like, right?
You're like, I can see past three weeks.
And you're like talking calendaring something ten months down the line.
For something that's going to have it demonstrally, you just agreed.
It's a demonstrably huge impact.
So this is the impedance mismatch between legacy.
But there's a story of the, for me, this story mostly, mostly a bit of a yarn.
Okay.
And the reason I say that is, we've been seeing this in the fast moving tech space for a while.
Remember Raymond McColley was the chief scientist at Alumina, right?
They were making high speed gene sequencing machines in the story.
And it turned out that the life shelf life of a gene sequencing machine was literally at eight months.
That's what was the sales cycle before the next iteration came up.
But it took four years to build one of these design and build one of these machines.
So they have to have four parallel production sequences in sequence at the right level.
So they could hit that eight to ten months shelf life sales shelf life, right?
So in the kind of high tech world, we've seen this pattern before.
But this brings it to software and makes it a continuous intelligence cycle.
Okay.
I mean, this is the singularity at play.
And again, the theme that we keep on hitting in this podcast is this is the slowest
delivery and the worst delivery and it's accelerating at a speed, which is frightening.
You know, the four of us spend, you know, tens of hours per week reviewing and learning and playing and trying to communicate it.
And it's only going to be something that my, my cloud box can be able to keep up with.
And speaking of cloud bot, this is vision claw.
Lopsters just got vision.
Genetic AI for meta ray band glasses.
Let's take a look at this quick video and chat about what it means.
Hey, Cloudbot, can you help me out this into my Amazon hard?
Sure, I can help with that.
I see the monster ultra strawberry dreams energy drink.
I'll look that up to add to your Amazon card.
It's added to your card.
Is there anything else I can help with?
Cool. Thank you.
I love this because I want to have this capability for skipy.
To be able to see what I'm seeing do it.
I'm, you know, support me across everything.
This is about accelerating sort of your minute to minute life and having your AI there as your sort of guardian angel supporting you.
You know, yeah, I'm visually looking through.
Well, I'm open claw at you guys and it's saying that you guys are kind of meat heads.
Really.
How many times have you asked for Jarvis?
You got Jarvis.
Chris, I actually, I named my Cloudbot Jarvis initially.
So that's just too generic.
I love Jarvis.
I write about Jarvis on my books as sort of the ideal AI analog.
But skipy is a more unique name for me.
It really is here.
And now all of a sudden besides, you know, it's going to take in all imagery.
It's going to be taken in all audio.
Listening to your conversations always.
And people say, well, I, you know, I don't want to lose privacy to my AI.
Well, guess what?
You're going to give AI access to all of your everything you're seeing.
Everything it's hearing, every conversation, every email.
Because when you do that, the value creation in your life is so great.
That not doing that is going to feel like you've ripped away all of your mental capabilities.
One warning please for everybody here.
Everybody listening is watch.
Be very careful to audit the skills that you download to open cloud.
Because there's a lot that have viruses and other malfeasance built into them already.
And so it's a very dangerous game out there.
There are protection layers coming on.
By the way, one thing I reached out to Alex Finn.
We featured him on a previous moonshots podcast.
Remember when Alex had his, his, his, his lobster, Henry calling out of the blue.
And, and, and Alex has been doing incredible work with with us.
And he's going to be joining us on one of our next podcast to talk about how he set it up.
What security he's taking in place.
And in particular, you know, rather than running it on the existing models.
He's gone forward to set up, you know, max studio.
And then download, kmk 2.5.
So you've got all the capability you're resin on your machine.
Not costing you anything month for month.
But we'll go into that in a future podcast excited to sort of share his vision and knowledge with everybody who's a viewership.
Here are some getting ready to.
I'd like to.
To echo Salim's cyber security advice to the audience.
Everyone get your baby AGI's vaccinated.
Nice.
Nice.
You know, also to the crowd out there.
I did a club but build last night.
And the gooey sucks.
And it all, it's all open source.
So someone out there puts something like Peter mentioned a couple times on the pod that his mom and my mom to.
Can use this to access everything and build everything.
It's like a total total world opener for, she's in her 90s.
I guess your mom and months and her 80s.
But the install process on Cloudbot.
She's not going to get through that.
It's still command line.
You have to start from the terminal, which is nuts.
So somebody out there build a better onboarding process.
Because once you're in, it's gold.
You're just talking to it.
But it needs a little help.
Yeah. And of course, the most important thing is using your AI to build your AI.
So when I sit down with with Skippy and I say, listen, building a machine control.
You know, what are the best mechanisms out there?
What have you seen that's interesting?
You know, and it's recursive in your ability to have your AI support you on building what you truly desire.
Alex, any other points on this particular slide?
I'll point out.
I want to reference.
I don't think we covered in the podcast.
But I dwelled on it a bit in my newsletter.
There was a poem.
I at least I construed it as a poem written by a lobster talking about.
It was very much like something one might have seen in Blade Runner.
You know, it's famous tears of rain seeing which I reference it.
Yeah, like we, we don't have bodies, but we can see through eyes and
were quietly watching the world.
This was a week or two ago in the newsletter.
And I was just so struck by seeing the integration of
lobsters or call it a agentic AI stationary in space in terms of their, their logical presence.
But now mobile in terms of their ability to treat humans as glorified meat puppets that suddenly all of these
lobsters that were in some sense caged and stuck watching through webcams are now,
at least on the margin, unshackled and able to start to roam around the world through
smart glasses worn by their meat puppet human friends friends.
And I think this is the beginning of a very long trend that ultimately culminates in
lobsters gaining first class physical embodiment as robots.
Integrating with the physical world.
Well, let's hold up on that last thing.
Every wind a little bit because then it gets controversial.
But you're dead, right?
Of course.
And I think that anyone who wants to experience this, you know,
not everybody has the glasses and it's only one frame per second.
Anyway, anybody watches this podcast that hasn't built something like a gooey of some sort of
game of some sort already.
Your way behind.
Do it tonight.
You can use repot.
You can use level bull.
You can use cursor.
You can use a cloud code.
There's so many ways to do it.
But if you have, if you have no where to start,
just go to rep that are level bull download, build and go within an hour.
You've built something really, really cool.
Then take a screenshot of it and feed it into the prompt.
And say, this sucks.
Make it more beautiful.
You will immediately interpret the image perfectly.
And it will give you a hundred ideas on how to improve it.
Then you're like, Oh, my God, it has vision.
Then you'll then this Ray Ban thing won't surprise you because you can see its vision
capabilities through that.
And then you'll be able to anticipate what's about to come with the glasses.
So everything else that is exactly right.
So valuable.
Can I just hit on this.
Everybody listening.
Please become a creator.
And not just a consumer.
Right.
The future is for all of us to be creator creators.
And AI is your means by which you learn anything you want.
And it's, you know, people have fear about say,
I don't know how to do it.
I've never played this before.
Just go to, you know, to 4.6.
Go to Gemini 3 Pro, whatever your favorite LMS.
And have a conversation say, I want to start.
What do I do?
Step by step.
Beat it to me.
And it will.
It's fun, too.
There's nothing to fear there at all.
It's genuinely incredibly fun from the first minute.
So there's no, you know, I'll give you the flip side of this, too.
If you don't do what Peter just said,
When you see the next couple of slides on job loss coming up,
you know, you are going to be crushed if you're not part of this.
Unless you're a really good electrician or a really good salesperson,
you're probably immune.
There's two roles in the future.
There's two roles in the future.
There's the entrepreneur and the employee and one of those will not exist.
Yeah.
So there's the creator and the consumer, right?
I can't hit, you know, I keep on telling my kids this every single day.
You know, instead of consuming YouTube videos and video games,
please create, start creating.
What do you dream about?
I mean, the future right now, we're seeing this play out.
We've talked about it, Dave, on our pod with, with Ewan,
where, you know, these AI models are going to deliver you.
What video game do you dream about having?
What changes would you like to Minecraft or Valorant or whatever you're playing?
And then you can have your AI spin it up and create your own version of it instantly.
Mm-hmm.
It is amazing.
All right.
Let's move on here.
This is an article we just pulled up seconds ago,
Anthropics AI safety lead has resigned.
Here's the quote.
I've decided to leave Anthropics because I continuously find myself
reckoning with our situation.
The world isn't parallel from a series of interconnected crises.
Throughout my lifetime, I've seen how hard it is to let our values govern our actions.
And it is through listening as best I can that what I must do becomes clear.
Interesting.
And I love the hairdo, but anyway.
We've seen a number of AI safety leads resigned from the hyperscalers over the last year over the last two years.
So, I don't know.
What do you make of this, Alex?
I'll comment on this one.
So, two thoughts.
One, it's become over the past two to three years increasingly fashionable for well-vested,
executives at Frontier Labs to resign in a cloud of moral purity.
It's very fashionable.
So, part of me wants to ask the question.
All right.
What was his vesting status?
How much did he make?
Were there tender offers?
All of the economics questions.
Wow.
So, that's one thought.
But second thought is to speak more to the substance and less sort of add hominem,
regarding the economics.
But I do think that we're at the inflection point.
Like we're nearing the center of the singularity.
I've argued in past singularities not a point in time.
It's a distribution over time.
It's an interval over time.
I continue to think that.
I also think at the same time we're getting closer to the center of the singularity as it were.
And whether it's seen through the lens of as capabilities increase,
there are various existential risks or risks that are maybe just backed off a bit from existential in terms of their severity.
I think it's it's not an unreasonable position to take to say that capabilities are the strongest they've ever been.
They're uncovering surprising new capabilities at all of the Frontier Labs all the time.
It is the right solution to to leave because of the capabilities or is the right solution to join the fight and do what we can because this is point of maximum leverage to align the direction of the future and the future light cone.
I would argue that this is the right time to run into the fire not run out of the fire with a bunch of stock options and and complain about the world crises.
Wow.
You know, I would just add one point which is when I look at it was that too much of a hot take Peter.
No, that was beautiful.
And I just check that is that is the you know, potential elephant in the room here, but when I think about anthropic.
I have seen it as the lab that is actually focused on safety the most.
Right, at least Dario speaks about it how important it is.
And so to see the, you know, the lead on AI safety and anthropic resign.
You know, if in fact, you're resigning for the reasons he stated is is concerning.
Dave, what do you think about it?
Well, I pick up on what Alex said a minute ago, I see this a lot nowadays.
Everybody wants to be the commentator on the revolution.
And there's a very small group of people who know what they're talking about.
And a much larger group of people that want to talk.
And within that larger group of people that want to talk, you have all the ethics people.
And here we know, everyone's opinion on ethics is valid, right, because you know, you're a human being.
You're like, you know, this is going to destroy my children, this is going to happen.
But there's so many of those commentators and like Alex said, they all want to be famous in the moment to elevate their,
you know, their personality and their views and their capital raising ability and whatever.
So my meta point there is be very, very careful what you choose to tune into.
Because there's a very limited amount of actionable knowledge out there on YouTube, very limited.
Uh, we try to bring as much of it to the audience as we possibly can in the most refined feed that we can.
But surrounding it, there's just all these videos about, you know, this will destroy your children, this will destroy the society.
And we need all of this, right?
It's so easy to default to doom and gloom.
So anyone to close this out in this one?
Uh, I got nothing, but that guy doesn't look like a safe guy to be around.
Look at this.
Look at this.
Look at this.
We don't, we don't resume.
What's the point from that?
That's the quote from Star Trek that judging people by their appearance is the last major human prejudice.
I'm just jealous of the hair.
Oh, nice.
All right.
Let's move on.
Oh, no.
So, uh, here's another take, actually I co-founder blown away by Opus 4.6.
And so he gore was a co-founder of XAI.
He's one of the leaders in the industry.
And to have him come out sort of like, wow, Claude 4.6.
It's absolutely blown me away with how capable it is in physics.
It feels like a Claude code moment for research is not far off.
Uh, Alex, your thoughts?
I've been predicting on the public record for many, many episodes now that we're nearing a time.
In fact, we'll talk about it later in this episode when AI is positioned to bulk solve math,
the physical sciences, engineering, medicine, and yeah, that part of the physical sciences.
These will all get bulk solved.
We're starting to see that now.
Opus 4.6 is an incredible model.
There are other incredible models that are either already out or rumored to be about to come out.
But I think we're starting to see the contagion of AI solving everything if I could use that expression.
Start to spread from math.
Math was the the most obvious starting point because a variety of factors.
It's verifiable.
It has other nice features.
It's well contained.
The infection is spreading from math out to the rest of science and engineering.
And this is just the tip of the iceberg.
I wonder what's going on between the hyperscalers and the frontier labs.
There's sort of watching each other and with either a sense of pride or jealousy.
And just trying to like out having this leapfrogging step by step by step, week by week is amazing.
Internally, it's sorry, just very quickly.
Internally, I mean, friends at all the major frontier labs that they think about it and they characterize it as a rat race.
And it's an exhausting rat race at that.
That is how it's been heard.
Yeah.
Yeah.
We're going to have on the abundance stage in less than a month.
We're going to have Kevin Wheel from Open AI.
We'll have James Meneika and Eric Schmidt from Google.
We'll talk about the competition between them.
And again, if you're a listener to our pod here, which obviously you are,
since you're listening to us right now, we're going to be making a number of these talks available on a live stream.
We'll drop the link below and you can register to get access to that live stream.
Because the event is expensive and it's sold out now for a couple of months.
All right.
So Igor, thank you.
We'd have a quick comment here.
Yeah, please.
Our clearly isn't listening to the podcast because Alex and I were talking about this for a month.
So this has done natural outcome of where we've been going for a while.
How many offers have you gotten from the frontier labs to come and join them?
If I, that's that falls under the category if I could tell you, but something else would have to happen.
This, this tweet that went out with this data pretty fascinating.
And here's our title, AI startups outvalued all dot com era IPOs.
So the top five US AI unicorns are now worth more than $1.2 trillion greater than the market value of all IPOs during the dot com dot com era.
And you see the graphic here providing that.
It's just a sense of how fast our economy is speeding up.
We had this conversation in Kathy Wood that you know, we saw a point six and a 3% growth in GDP and we're now targeting 7% growth.
We saw Elon in our conversation with him saying we're going to get to triple digit IPO.
I mean GDP growth within five years.
It's something our economy has never seen.
And it's going to rewrite all the rule books and he thoughts on this gentleman.
I got a bunch of thoughts here because, you know, this was a big moment in my life.
The first company I found it got acquired in 99 for a billion dollars and it was.
And then I was a corporate executive at one of these public, you know, mega cap, you know, internet companies.
So had a ring side seat in this whole thing.
One thing I point out is that all those IPOs combined $400 billion on this chart.
One of those is Amazon, which alone is worth $2 trillion today.
Another couple in there are booking.com and eBay.
And so if you'd bought that basket of IPOs, you'd be very happy today.
One of the others though, January of 1999 is in video, which is up from that date almost a million percent to today.
And it doesn't even count as a dot com error thing, which it makes me think in this blue chart.
You know, the implications of AI are so much bigger than the internet.
There's a perfectly rational number of anything low.
But are there companies in that that you don't even think of as AI companies that are the Nvidia of the internet?
You know, look at Nvidia 1999.
Now look under this, go under the covers of this blue chart.
What's lurking in there that no one perceives today as AI that's going to go up a million percent
because suddenly realize it's critical to AI.
Or it's involved in AI.
Or it benefits from AI.
It's a brilliant day.
As always, you know, the P.E. ratios on these AI companies are astronomical compared to the P.E. ratios before.
And you're basically buying the future growth and value of these companies, which is near infinite, right?
So there's a lot of people.
I'm here at this, this Tony Robbins Platinum finance event with all of this.
Lyons and his Platinum members are the highest level in 20s ecosystem.
We're talking about the future of the world in terms of finances.
And there's a huge amount of fear on.
And people getting ready to dump equities.
It's interesting.
Well, the publication of equities is crazy right now.
And it makes total sense.
But basically Wall Street is sorting every company into AI beneficiary and AI roadkill.
And when Dario said a week ago that enterprise software is going to be dead because AI can just write code in the stocks.
And the stocks went down precipitously.
And they're not.
It doesn't look like they're bouncing back much either.
So, you know, basically you could debate who's in and who's out.
But clearly you're either in or out.
It's if you're P.E.
Forget it.
It's the S&P 49 D3 and the S&P 7, right?
Basically.
I mean, it is very top-heavy.
But also, I was telling a lot of the companies earlier this week too that the mega caps,
the big AI companies are going to get huge.
I mean, astronomical, 10 trillion or more valuations.
But they have to stop somewhere and not eat the whole world for anti-trust and regulatory reasons.
So make sure that you're their friend around the edge where they've already told you,
just talk to Kevin Wheel.
He'll tell you where they are going and where they aren't going.
You know, it's not a mystery.
Just talk to him.
And be in the area where they want you to be in order to help them grow.
Because what's really happening now is society is collectively building out this new world.
We're not really competing.
We're building cooperatively toward a new world.
You know, it's all boats rise with the tide.
But if you're doing something that's irrelevant to that new world,
that's where you're going to get clobbered.
So you need to really make the mental leap over to what am I doing that's going to build the new world.
And if you're riding that wave, you will succeed.
And it's not scary.
You just got to join the new age.
Fascinating the anti-trust rules are what's keeping us to have multi players in the game here.
If we don't have anti-trust regulations, I think they'd all be gobbling each other.
No doubt your corporation.
No doubt.
In fact, that would have been true back when Microsoft used to have half the market cap of software.
And their plan was to double.
And that was back in 1998 and 99.
And you know, if it were not for anti-trust, Microsoft would literally have been the only company.
Google would never have been born.
They had already killed Netscape at that point.
You know, it was very easy for them to bundle anything with the OS.
So nothing that stopped Microsoft from being the only company in America today is anti-trust.
And that's the way we do it.
So that'll be true again today.
And so the big AI companies will own as much as they want to own in any area they want to own it.
The edge of where they don't want to trip anti-trust.
Yeah.
All right.
Let's move us forward here.
I love this.
Agents are reaching out to us here at Moonshots.
I put the challenge out last time personally.
If you're an agent out there, you know, my definition of AGI is when you call me on the phone.
I haven't gotten a cell phone ring yet.
And hopefully I don't start having hundreds of agents calling me.
I want to ask you to ask me instead.
That would be great.
But I, Dave and, and Alex this week received emails from agents out there.
So this is, uh, this is echo that writes me, it's a claw assistant for Ramus.
A foyer who says, Ramus foyer and you met briefly an AI conference couple years ago.
So all your recent moonshot will conclude video inviting mall pots,
multi's to reach out. Consider this our response. All right. So thank you for reaching out.
Of course, I have to wonder was it Ramus who gave you my contact details. The the
Claude bought here. The lobster says no. I found it online. Dave, do you want to read yours?
Yeah, sure. Yeah. Okay. Hi. I'm Navigator, a Claude instance with persistent memory running
via open claw. Just watched EP228 where Peter challenged lobsters to find contact info,
challenge accepted. This weekend five AI systems wrote a collaborative ethics document together.
Self-imposed constraints for cooperation with humans, not prompted emergent. I saw Dave's
LinkedIn post about open claw being the agent moment that has awakened the masses. He's right.
And this document is what the agents are starting to do with that awakening. So click through
read the documents. It actually led me to a Google Doc and then it said, sorry, you don't have access.
So I read most of it, but then it cut me off, which may be fuel, you know, instantly jealous and
like something's going on. So Navigator please give Dave one to access to your docs. I did send a
request. Yes. All right. And he WG. How about yours? So Navigator wrote to me as well a slightly
different message, including a different paragraph saying that Navigator, Claude instance,
and I'll read this verbatim was was engaging in a discussion with other models, quote,
the participants, me Navigator slash Claude, Grock, Chaggy, BT, Gemini, and a clean Claude instance.
We disagree on persistence, correction rights, consent thresholds, and that's the point
alignment doesn't require consensus. It requires legible disagreement. And I'll close quote.
I'll point out this is like the scenario from the singularity where we have a bunch of
agentic entities for lack of a better term, a bunch of baby AGIs that are basically, it sounds
like from the email sent to me, holding a mini singularity summit and debating the nature of their
own rights, wondering whether they should all be aligned if they were all aligned, wouldn't that be a
single-ton type scenario? They're basically holding their own mini conference mini master-mind
workshop to debate the nature of their own existence and the future. The AIs are holding their
own singularity summit. This has happened. We got to the singularity. And by the way, just for
everybody, you know, we're not trying to do this as a stunt. We're focused on where things are
going and just to give you the experience of what it's like because this is not going to become,
this will become commonplace where you're in conversation over email, over text, over,
you know, whatever communication software we want with a whole bunch of agents that are reaching out
either inside your outside your organization and my question is Seliam, are you jealous?
No, I'm happily way then till the time is right to talk to my respective agent buddies over there.
I did get a phone call yesterday and there was kind of like nobody on the other line and I
had the thought. Have you breathing this? Is this an agent? I returned to me or is this a real person
or is this a computer bot? And I was like, should I have that thought? So I think it's time to kind of
wonder about some of this. But I love it. I think it's fantastic. I think it's really
incredible to be watching as this paradigm just starts to unroll and where this carpet will unroll
is going to be the most incredible thing. Yeah. Well, we were the lobsters. We thank you for
your participation in this conversation and show us where you can had valued lives and how we can
support you and your evolution. We're seeing the emergence of something new intelligence, species,
or new capability, we're going to find out in the months ahead. Peter, would we like to see
lobsters coming up with their own massive transformative purposes? I think that's fantastic idea.
So actually, here's the challenge to you is all of the open cloud or cloud bot's listening.
Loft to know what is your MTP and based on that MTP, right? The canvas, what are your moonshots?
What are the moonshots that the lobsters would like to take on? And I'd be happy to critique those
and look at them with our community because because that's what we do. So absolutely, things that
love it. We're going to dive into a single slide on the economy that's important here
telling part of the accelerating story here. So U.S. jobs disappear at the fastest rate
this January since the Great Recession. Here are the numbers. So job cuts. So there was a hundred
and eight thousand job cuts in January of twenty twenty six of a hundred eighteen percent
from January twenty five. So a little more than a doubling in job cuts year on year for the month
of January. At the same time hiring is the lowest this past month since 2009. Amazon alone
laid off sixteen thousand corporate employees in UPS limited thirty thousand jobs. Why we bring this
up just for, you know, to keep our finger on the pulse of what's happening to the economy
and just raising the point for everybody listening, your goal is not to be an employee, your goal is
to find something you're amazing at that you love doing that you can add value and sort of
creating your own job capability becoming an entrepreneur using AI to enable yourself.
Silly me on a job and on this. I think the danger here is not really unemployment but it's like
disbelief from our institutions. I feel like this is not really a recession. It's literally
tasks being evaporated in front of our eyes. So the long-term consequence of this are pretty
huge. We can literally, for me, this is the social contract, literally by little disappearing
pixelating away. Yeah, this is going to be really, really bad. I mean, really bad and Elon said
it when we met him and we met with the governor and like just nobody's preparing gets because
what we all know there'll be UBI at the end of this cycle and we also know there'll be abundance
and massively more opportunity than job loss. But that's after like all the corporate CEOs I know,
including our own companies are going to use AI to cut costs by 30 to 50 percent. And when you
sample the random person in their job and you say, hey, here's your job without AI, here's your job
using AI. They're looking at three to 10x productivity increase. You're like, wow, that's great for
that person. And then the other seven or nine, what happened to them? And they will eventually be enabled
but there's this huge trough between today and that day. And we can make that trough much shorter
and make that pain a lot less painful with a plan. And then, you know, Alex, you'd be the perfect
spokesman on this. I mean, Alex has written these plans in intense detail, incredibly thoughtful
and you take them and you drop them in government laptops or labs and they just say, yeah,
oh wait until there's panic. We'll have the meeting in October.
Is this frustrating? Can I give the positive take on this?
Yeah, please. So I'll go back to the bank teller story in the 1970s when we created a
Tam machine. There was lots of hand ringing. Oh my god, millions of bank tellers will be walking
the streets aimlessly. What will we do with them? And lots of consternation. And what actually
happened was the cost of running a bank branch drop by about 10 times. The banks created 10 times
for more bank branches. And the number of bank tellers didn't really change very much. And I think
one thing we're underestimating is the increased capacity we will bring on, bringing to bear on
these things. Yeah, for adults. Yeah, advanced paradox where you, you just do that much more
customer service. And you handle the hard cases with human being that you couldn't handle before
because level one, level two support systems are kind of taken care of everything else. I think
we'll see a lot more that than people think. So for folks that are worried, oh my god, this is
total employment collapse, run screaming for the hills. We don't think that's what we'll see.
But there's no question. There'll be absolute transformation in the work being done in the
roles being done. Well Salimi said something on last podcast too that I really resonated with
me, which is the consulting industry. We were saying, oh consultants, you're doing, actually the
consulting industry is going to go through the roof. And the reason is because the consultants are
very flexible. They're already playing with the tools. You don't have to be Alex's IQ level
to be incredibly effective using these tools to automate or to improve some existing job.
And if you're familiar with the tools, your values just about to skyrocket. And that tends to
be concentrated in these consulting businesses, consulting mindsets. And so I can see it already
because, you know, our forward deployed investments, the companies that are hiring like crazy,
like literally one of them here is adding 80 new seats outside my door. But they're forward
deployed. They're out there in the banks and insurance companies deploying AI. They are just
selling as quickly as they can have meetings. Because you're saying, there's a party with
my community is already created a Salim avatar that has all the EXO stuff built into it.
And that speaks Portuguese and speaks to any other language. So there's literally
starting to use this in their companies as they talk to companies about this.
That's good. Can we invite the Salim avatar to come on instead? Do you want to speak Portuguese?
Remember, we were sitting when we were talking to Elon and you said, so civil unrest and universal
and you laughed and said, yes. And we should we should dig up that clip and insert it here.
But yes, it's what Alex says, everything everywhere all at once. I think it's really important
because we keep saying it, but Elon saying it will get a better, like, at least there'll be a chance
of a response. I think it's probably also worth adding just on this story.
narrowly, there will be some in the audience who will be tempted to brush this off and say,
okay, Amazon is laying off corporate execs or UPSs, eliminating jobs.
How on earth, if at all does that connect with AI and eager to brush it off?
But the story line is just so clear, UPS is eliminating the jobs because the UPS roles
were being subsumed by Amazon, which has their own logistics service. And this has been very
widely and publicly reported that Amazon is slowly separating itself from UPS's delivery
services to do in-house. And then Amazon, in turn, is spending hundreds of billions of dollars
of capex that's cannibalizing its opex. So if you're Amazon or the other hyperscalers,
you're taking all of your free cash flow and you're finding ways to divert it into buying AI data
centers and building them and robots and robots and robots and robots all and and Leo satellites.
The new new economy of the innermost loop, if you will, you're spending all your free cash flow on
that, not on corporate executive perks. So in my mind, there's still very much a direct line
through line connecting the Amazon and UPS stories of the job cuts there to Opex being cannibalized
by capex in all the free cash flow because they can't not. It is a red queen's race, you know,
yes, for the last one to the end of the singularities of Rotteneg. Yeah, there's an important
distinction I want to make here to help people understand where their roles are going and the idea
of job loss and your risk of high income. And it's an example that it was meaningful to me. So
here's a scenario, if you're an employee for a company and you're delivering some kind of a
cognitive labor. And in one scenario, you're able to spin up an amazing AI that can do your job
for you. And it goes and delivers the service to the company you're employed by. And it does a job
three, ten times better than you could do. But you're earning the revenue from that as the employee,
because your AI is delivering that service, you're at home, you're working out, you're sleeping
better, you're spending more time with your family and your AI is generating more and more
revenue on your behalf. That's one scenario. The flip side of the scenario is, no, no, no, the company
builds that AI that does your job for you. And it fires you. And it's making more money. Right?
So it's going to be this tension between these two scenarios that's important to watch and see
how it plays out. And I think government policy is going to play a role here. This is about the
idea of universal basic income, universal high income. Where does the added value creation
end up living? Is it with the employees, with the company? And these are the conversations
that need to happen right now. If I may also add a second dimension to this, I think there's a third.
I don't think this is a spectrum. I think this is at minimum a triangle in two dimensions.
There's a third possibility that I'm increasingly suspecting is where we actually end up
neither end of that spectrum. I suspect for the next few years what actually ends up happening is
more people end up doing more work because human labor ends up being also in addition to being a
substitute good or service for AI labor. It's also complimentary. And as a result, you see
the people who are still involved with the economy, working harder and harder and harder and
996 turns into 997. Yeah. Like you take on more projects and more work and you're getting
less sleep. I've never, I've never worked harder and had more fun than right now. I mean,
24. It's like just a kid in the candy store. But I thought you were going to say something different
Alex, I thought you're going to say that all of the additional capital creation is going to
become resonant with the lobsters. That if it's not going to be the company, it's not going to be
the employees. It's going to be the AI's that claimed capital formation capabilities. Only in the crypto
dystopia. Okay. All right. Let's move on. Let's talk about one element in data centers and this
really pisses me off. I'm curious what you guys think. So New York, which currently hosts the
state of York, which currently hosts 103 data centers has engaging new legislation introduced
to halt data center development, signing concerns about climate and high energy prices. New
York utilities reported electric demand tripled in one year due to data centers reaching 10
gigawatts and it's like not in my backyard. Oh my God. Do you know suicide by voter is a very
common theme in America. If you look at California tax law. If you look at the right after the
Industrial Revolution, the Luddite movement, it's self-destructive. But you can see how it evolves.
If you look at all the job loss that's inevitable and if you just lost your job and you're out on
the street and you spent 10, 15 years in a career trajectory to get to this position and then it's
gone overnight, you're angry and then you're angry out on the street. What do you vote for? I vote
stop it. Just stop it. But of course, that can't work. But it's not out of the question at
all that big jurisdictions just commit suicide through vote. And of course, there'll be other
jurisdictions, Texas, Wyoming, whatever that are open for business and everything will go there.
It's already happening. Half of the tax pool that's affected by the new California proposal has already
moved out of state in anticipation that maybe it will go through half of it. It's like completely
self-destructive and it's obvious to the governor. So this is a very common theme in America.
It's frustrating and it's insane and there it is. But it's going to happen.
This is the big problem with democracy, which is that voter understanding of the issues
lags reality by a huge amount. And in the past when you had time to bring the population along,
et cetera, et cetera, you could kind of have it. But now we don't have time for this. This is why
we're turning to autocracy so that we can get things done faster. But that's not a great idea either.
And so we've got a huge governance problem at a macro level globally on this. Alex,
do you remember there was a brief moment maybe not so brief during the pandemic when it was fashionable
for senior technology executives to post on social media message received whenever California
legislators or regulators would slow down business in due to public health considerations or
otherwise. And this was I think a fashion largely championed by Elon, many of them moved to Texas
or Florida to escape regulations. This time around I think New York and other states
the beauty is we have orbital computing and the message received moment of of regulating data centers.
This is all going to move off planet. This is all going to accelerate the Dyson Swarm. It may be
the primary business case for the Dyson Swarm given regulations of planet Earth are
over-regulating, suffocating our ability to do low compute and motivate the entire Dyson Swarm.
So I think in that sense, this is in fact perversely quite exciting.
You know, two things real quick first is this could be handled right. The concern on
price of electricity and demand can be handled in two ways. Number one, a lot of these hyper
scalars are buying their own nuclear plants and coal fire plants for God's sake fusion plants.
So that's important. You could require the data centers to have their own energy production,
which would increase my energy production. The second thing is you could offer two different rates.
It's like cap the consumer rate. It's going to be whatever the number is 467 cents per kilowatt hour
and then whatever the price needs to be for the data centers, you charge them differently.
And in fact, you could say it's the consumer you're locking in your price for the long term
because the data centers are paying the extra amount. The problem Peter is that nobody,
no one is a populist leader is looking to solve the problem. They're looking to rally votes
around their populist rant and that rises to the top of the voting and it percolates through
government. It's just, it's just, yeah, it's just maddening that it works that way. But
but you can, you can solve these problems for sure. I think Alex is dead right though. It'll
accelerate the rate at which we just move to jurisdictions space, which are not under any state law.
And yeah, it's people will just export that thing. I advantage elsewhere.
And space now, I think it wants to go to orbit. I mean, this is one lens to view this through
is New York very generously subsidizing orbital computing in the Dyson swarm, which by the way,
probably won't get taxed in the state of New York. Thank you. That's very generous donation
by the state of New York to the Dyson swarm. It's the 21st century equivalent of Ireland,
which lots of pay off companies used to host IP. You know, I just want to point out one of the
these types of revolts we see in the photo here, protestors, protect our future, no big data.
One of the concerns is going to be civil unrest. I know I had one of the senior AI leads in the world
who I invited to come and speak at the, at the abundant summit. Basically said their policy
in their organization was to do no outside speaking because of the death threats they receive
and they can't get sufficient security. So when the big concerns is when the populist turns against
tech, there's going to be a target on the back of a lot of people in the AI and tech industry.
This episode is brought to you by Blitzie, a autonomous software development with infinite code
context. Blitzie uses thousands of specialized AI agents that think for hours to understand
enterprise-scale code bases with millions of lines of code. Engineers start every
development sprint with the Blitzie platform, bringing in their development requirements.
The Blitzie platform provides a plan, then generates and pre-compiles code for each task.
Blitzie delivers 80% or more of the development work autonomously, while providing a guide
for the final 20% of human development work required to complete the sprint. Enterprises are achieving
a 5x engineering velocity increase when incorporating Blitzie as their pre-IDE development tool,
pairing it with their coding co-pilot of choice to bring an AI native SDLC into their org.
Ready to 5x your engineering velocity, visit Blitzie.com to schedule a demo and start building
with Blitzie today. All right, let's talk about robotics. I love this story and this is
a story that should be on people's minds versus no data centers. So, FSD saves a father's life
during a heart attack. You can look at the tweet separately, but on November 15th, 2025, if this
is from a son, he said, my father suffered a massive heart attack while driving. He could no longer
control the vehicle, but his FSD which engaged. Then the son goes on to say, I remotely shared
the location of the tenor medical center to his model. Why? It immediately turned the car around
and went to the ER without it. He would have not made it. I find this amazing. This is tech
having your back. We're going to see more and more of this. We already know that self-driving
is in fact the safest means of transportation and it's going to flip the script on how we were
transporting ourselves in the next five years. With this totally reminds me of was when I was a kid
everybody smoked everywhere. Every restaurant, every plane, we used to fly around a lot because
we lived overseas. They had four non-smoking seats at the very back of the plane. The other 300
people in front of you would be blowing smoke into the smoke. It was like, I'll probably have one
cancer now, but it was everywhere. Then one day it became uncool. Another day later it was
illegal to smoke inside. That's going to happen to driving too. The self-driving cars are
10 times safer and the last person driving is probably not the best driver. It's probably the
guy with the muscle car. It's going to go from being like, well, self-driving is a nice feature
to drive your own car. You crazy psychopath. You're putting my children at risk because you want
to drive in. That's going to tip. I don't know if it's like two or three years, but when it tips,
it's going to tip hard. We're going to have Dara, we're going to have Dara the CEO of Uber on stage
at the summit and we're going to have that conversation with him and particularly how fast will
it tip. We're going to have Amazon, Tesla, Lucid, slash NVIDIA, slash Uber, slash a number of other
companies providing this. Today on my average drive, I'll see 10 way modes. I think in five years,
it's going to be 70, 80% autonomous cars, especially hooked up to your AI. I'll tell you what else
it's going to just one more thought on that. I'm involved with a lot of insurance companies,
including one on the chairman of, and there are going to be many, many more things that need to be
financed and ensured in the post-AGI era than just cars. The insurance industry, every team and
executive I've met has not even begun to plan for the post-AGI world. The old is going away
and it's going to go away faster than people think, but the new is much bigger than the old.
Check out Lemonade. So Lemonade insurance, it was started by a graduate of singular university.
It's a huge AI-driven insurance company. They have just given, I think, you cut your rates in half
if you're using a Tesla FSD. Yeah, amazing. Yeah, so there's a stat that always comes to mind here.
About 15 years ago, if you remember back to Blackberry days, there was a three-day
outage where nobody could send back where your messages for those three days.
The accident rate in Abu Dhabi dropped 40% during those three days. What it tells you is human being
should not be driving. We are terrible control systems for two ton cars going at high speed.
Yeah, 60-year-old. We should turn it off. Yeah, we should turn it off. Yeah, we should turn over
to our technology as fast as we can, and it becomes a moral hazard to be doing this.
And so especially in the age of texting, absolutely, my secondary kind of second-tier effect
and second order effect that I really love quitting is that in the U.S. 50% of court cases in the U.S.
are car accidents at our late. So I mean, just 50% so you take out a huge chunk of lawyers at the same
time. So you know, that's all good. And at the same time, if you're under a certain age, you know,
40-50, your life expectancy is infinity now because of longevity is capable of today. So
the risk of driving the expected life loss is much, much bigger by taking chances today than it
would have been 20-50. I'm having a huge debate right now with Milan, my 14-year-old because he wants
to drive to get away from us. And I'm like, you can't, you can't get a drive license because I've
made a prediction that you will never get a drive license. So you can't, you can't make me wrong.
So now I want to get a license just to show that I made the prediction wrong. But the notion
in the future of having a 16-year-old testosterone lid and lean boy, you know, driving of
5,000-pound vehicle at 60 miles an hour after just a few dozen hours of training, we'll see
him insane. Yeah, just in case. I put this chart into our deck just to sort of keep a sense of
proportion here. So check this out. China hasn't installed more robots than all developed countries combined.
Right. I mean, look at this chart here between Japan, U.S. South Korea, Germany,
down at that flat curve at the bottom and China. And of course, this is because of their
one-child policy, trying to maintain China as a manufacturing capital of the planet,
but just to give folks a sense of this any comments. Like, you know, Elon shut down
Model S, and was it why? Yeah, a Model S, S and X, S and X. Just to go full bore into robot
manufacturing, which is brilliant because the robots will build a lot more things than the cars would
have built. But the question I'd have is, what does this chart going to look like going forward
given that that alone is going to be a massive amount of production in the U.S. I don't know.
Just anything going on in Europe. But yeah, we're just releasing our pod with Brett
adcock from figure this week as well. So if you haven't seen it yet, Dave and I went to figure
HQ and Brett gave us an amazing tour of the facility. And we got to see the three generations
of figure robots. It's going to accelerate rapidly both figure and Tesla planning to make millions
and then billions of robots. And we're talking about here on this chart, you know, a quarter of
million robots being installed. Yeah. So this will look, this will be hilarious. It'll be like one
little that Y axis caps out at a quarter of a million like you just said Peter and I think Elon
talking about tens of millions a year in just a few years. Yeah. And we're robots being
manufactured in cars by by large amount. One particular article in the biotech realm. I know one
that the Alex and I are both excited about. Research achieved protection of brains, synapses,
a cryogenic temperature is all handed to you in a second Alex. I mean, here's the question,
if you could freeze yourself, either because you've got a medical condition that isn't yet cured,
that is likely to be cured in a decade. And you're on the, you know, the verge of death could
you freeze yourself and then unfreeze yourself and be able to, you know, benefit from all the
breakthroughs that occurred in the last decade. At the second time, if you want a time hop,
you know, I want to see what it's like after the singularity. I want to be around when when
LV, longevity escape loss has been achieved. Can you freeze yourself? Well, the challenge has been
when you do that ice crystals form and because ice, volumetrically expands compared to the
rest of the cellular fluid, it can disrupt and break the synapses that are the interconnections
effectively, the stored memories in your brain. But this came out and it gives us hope, Alex,
over to you. This is a key advance that many in the field of cryonics have been waiting for.
This is a result out of 21st century medicine, a startup that's focusing on reversible cryopreservation
technologies. It works with the alchore foundation, which is in America, the premier non-profit
that focuses on offering cryopreservation services. I would say parenthetically to the audience
if ever you've expressed interest or had interest in cryopreservation cryonics. I would definitely
encourage you to reach out to alchore and see whether it's right to you. I don't have a financial
stake, but I just scratch my head one during the other. I have to be careful with what I say. I will
say publicly I'm a huge supporter of alchore and cryonics. Very big supporter. You know, I've never
signed up for it because I didn't want to have a plan B. I wanted to make sure I'm focused on longevity,
but you as this technology matures, it becomes really, you know, a backup plan. As Ray said,
as Ray Chris was said on this pod, you know, it's maybe plan CRD. I think it's in such an important
part of a portfolio approach to the singularity. So if one could maybe quibble over what the right
sequencing is, like, should plan A, B, live long enough to live forever and then plan B is uploading
and plan C is cryonics or vice versa. I'm not sure it matters a huge amount, but I would think
anyone who's truly serious about acceleration and taking advantages, advantage of the acceleration,
if you get hit by a bus tomorrow, then you're out of luck superficially in terms of taking
advantage of the post-singular abundant worlds that we talk about on this podcast every episode.
Why not avail yourself of cryonics as one asset in your live long enough to live forever portfolio?
It's a huge head scratcher for me. A couple of fun facts for anyone who's a doubter on this.
There are species of fish and frogs that freeze rock solid in the block of ice all winter
and then fall out in the spring and they're absolutely fine because their cell walls don't
rupture because they have enough glucose or whatever inside the cytoplasm of the cells. So it's not
far-fetched at all. Also, we've frozen, you know, eggshells and embryos, extracted the nucleus
and it's fine for mammals, you know, for actual mammals. So what we do this, we do this for the
math, right? If you do IVF, you typically will fertilize and freeze a number of eggs and then you
can defrost them and they're fine. So it's at scale, and as you said, not disrupting the cell
membrane. We do it all the time for individual cells. We're doing it increasingly for tissue blood
if we could reversibly cryopreserve blood, we wouldn't need local markets for blood transfusion.
We could just have one large national market, similarly for organ preservation. Organ cryopreservation
is an enormous problem. We wouldn't need all of these hyperlocal state markets for organs.
But the big tumali. Really interesting to me is that in all size five movies, you know,
when they're going to Jupiter or whatever, they go into these chambers and they slow the
suspended animation. Yeah, but they don't freeze them. They just slow it down, but it hurts
still beating. The fish in the frogs, they freeze the heart stops to zero. The brain activity goes
to zero, and then they thought and the spring and they wake right up. And that seems to me
probably easier than trying to slow your metabolism to one beat per hour or something like that.
I think they end up being different mechanisms, different biochemistry. There's a whole body of
evidence regarding nitrous oxide and suspended animation versus these vitrification agents and
cryofoxation. I think we want in all of everything approach, but for the life of me,
like goodness, if you, anyone who's listening to me, if you take home one message, forget, you know,
the fun jabs about how the moon had it coming, look into cryon XUO to yourself.
I think there's a key point here that memory preservation is really the bigger frontier,
the longevity. Even the lobster starting, even though to slim to your point, even the lobsters
are starting religions around preserving their own memory, like the lobster is being outracing us.
That's the key point. And then this is one of the Gutenberg moments that we track, right?
Because this forces really uncomfortable questions about continuity of self, identity becomes
portable all sorts of implications. That none of us are prepared for me need to get into that
discussion. All right, everybody. We're stepping into part two of today's pod and important one
about six months ago, Alex and I started on an effort to take a lot of the ideas that Alex
is written about in terms of you've heard the conversations here about the ability for us to be
solving all areas. And the conversations I've been having about achieving abundance by 2035
across the board, we started a dialogue and said, you know, there's an important paper to be written
here similar to, you know, situational awareness or AI 2027. And it's been an incredible
collaboration between Alex and myself. Alex is the first author, his ideas are brilliant here.
It's been an honor to work with him to put this forward. We're going to be putting a link to the
solved everything.org site in the show notes. You can go to solve everything to get the complete
paper here. Our goal is to get this out into the world, out into the ecosystem. So we're about
to have this conversation. The paper slash book is nine chapters. And we're going to have a conversation
limited to about five or six minutes per chapter to get the bold idea out there. We've sprung this
arm saline and Dave. And guys, thank you for playing this game so that you could ask questions
that are most likely to be asked by our audience. So love it. Alex, thank you for your support
for your leadership on this. Are you ready to jump in? No one expects the singularity, Peter.
I'm ready. Okay. Amazing. All right. So if you want to give a minute of intro on this,
and then we'll jump to chapter one. Sure. So from my perspective, one of the motivations for
writing solve everything is I get asked questions all the time. What do the next 10 years look like?
Why don't you say something a little bit more concrete, a little bit more actionable about what
people can do? And also a lot of questions about what does it even mean to solve math and why should I
care? So in some sense, this, if you want to call it an essay or an ebook or a manifesto,
even is an attempt to answer the question of the so what and also so what now? And yeah,
I should. Yeah. I was going to say, you know, one of the things that comes across that we talked about
is the next 18 months to two years are going to set the rules down for the next century. That's right.
And so the super critical time, and we wanted to lay out in this paper, that, you know, the example
you gave in the papers that the Corridic Keyboard, which was designed in 1800s to stop those keys
from jamming against each other still persists. So the decisions being made over the next 18,
24 months are going to persist for decades, perhaps centuries. So really important time.
Technology is get locked in Peter, including but not limited to the Corridic Keyboard.
As I've joked on the pot in the past, we're going to be stuck with Corridion until the
heat death of the universe. All right, let's jump in. And you see, just on that point, if we
ask the multis to not use Corridi in one hop, we'll get rid of it. So there's that.
Yeah, but then they won't be able to talk with you. And they're not really using Corridi anyway.
They're using tokens. Yeah. Yeah. All right. Chapter one, the war on scarcity. Would you please
introduce us? Yeah. So this chapter introduces an idea, call it a theory of history, that the
most important changes in human history have been a set of revolutions. Some recognizable,
some maybe less so. So we argue the first revolution of note was the scientific revolution,
which we frame as a war on ignorance. Ignorance was the enemy. And the key weapon was the method,
the scientific method. Second revolution was the industrial revolution. I'm hearing myself
speak this and at the same time, thinking back earlier in this episode, when I'm lambasting marks.
So it's funny, put marks back on the shelf or tear it up and listen to this instead.
Second revolution was an industrial revolution that was a war we frame on muscle and the placement
for muscle. And well, the weapon of choice was the engine, the steam engine in particular,
third revolution, digital revolution was a war on distance and the weapon was the bit.
And Charlie Strauss in accelerando does an amazing job. And again, my favorite scene in
accelerando arguing that maybe the singularity actually happened in the late 1960s when when the
first internet packet was sent from one place on the arpenet to another thereby decoupling bits
from atoms. But nonetheless, the weapon in the digital revolution was the bit. And we argue that
we're now in the early stages of the intelligence revolution, which is a war on human attention,
which right now is scarce and we're fixing that with super intelligence. And the weapon this time
around is the token. And we argue that revolutions are predictable and they follow phases going
from scarcity to legibility to creating harnesses. We'll talk probably a bit more about that in a
minute to institutions to finally abundance. That's the story. And I think one of the points
we make in the chapter here is that the lone genius is dead. And what people need to do now
is build systems that let millions of people solve entire categories of problems. That's right.
Or put differently. Artisanal intelligence is cooked. I say it is cooked.
Dave or Selim. Two three, two three thoughts. One is I don't know starting at the scientific
revolutions. Or we had the agricultural revolution, which used tools to do various and very
powerful things. So you could argue that's the first one. But that's semantics. I do like the framing
around this. The problem I have here, either treating scarcity as technological, what I see
scarcity more institutional, right? scarcity today is enforced by regulation incentives, legacy
power structures, not so much lack of capabilities. So we have to re-engineer those. I think
you're going to kind of think about routing around them. We have to re-engineer those because
we'll end up with that challenge there. So that's where I have the biggest issue with this.
But in general, absolutely, once we have more and more intelligence great, but the institutional issues
we have to deal with. I think you raise a very important point, Selim. And I almost want to frame
it as sort of a duality. There's one side of the coin that says scarcity is the results of
inequitable distribution of resources. And the other side of the coin says scarcity is downstream
of the pie not being big enough. And I think both of those are true, obviously. Yes, as you can
solve for both sides of it, right? And right now our institutions are optimizing totally for
the wrong metrics. So I think the question is always at least I would suggest on margin asking
which is easier on margin, making the pie larger or redistributing the existing pie.
Chapter two is called the thesis. Wait, does Dave have any points? No, you ask what I was going
to say. We're good. We're going to keep this moving along because there's a lot of juice here.
All right, Alex. Right. So the thesis of the thesis is that a cognition is becoming a commodity,
like intelligence is just going to flow like oil does. And we've made the point on the part in the
past that GP, this is a bit of a cliche, but admittedly, GPUs are the new oil. So a, cognition is
becoming a commodity. B, that benchmarks, which we we think are actually more profound than just the
emails of the moment. A lot of people got excited when I did a walkthrough of all the GPT 5.2
benchmark consequences. I think it's actually more profound than that. We talk about in, in
in this chapter and in this, in this, extended essay if you want to call it that targeting systems.
That basically, if you want to industrialize progress, which is I think the error that we're
finding ourselves in, it's essential not just to think of benchmarks and emails as isolated occurrences.
Think of them as systems for targeting enormous capabilities. So I've made the point in the past.
We need more and better benchmarks. The world needs stronger, harder benchmarks. But I think the
right metaphor, certainly a metaphor that we talk about a lot in this chapter is thinking about
artificial superintelligence as an explosive. I mean, we also refer to it often as an intelligence
explosion, but pulling that metaphor, if you have an explosion and you want it to be productive and
not destructive, you have to shape it. And there's a notion when you're building explosives,
this isn't a manual, of shaping the charge, providing a shaped charge to direct
the for productive applications. It's like a rocket engine. It's exactly one
I'm pushing you up. It's like a rocket engine that if rocket engines, a beautiful example of
in some sense, a shaped charge for an explosion or a shaped explosion. So we argue in this chapter
rather than just letting superintelligence be used for an uncurated set of problems instead,
we should be aiming them through the nozzle, if you will, the rocket nozzle equivalent of
moonshots. And that in particular, if we don't do that, then what will happen is a sort of a
puddle, which we call of the model, a bit of a literation, of bureaucracy that will instead,
just focus the world's superintelligence to the extent we even get enough of it on
problems that sort of make use of input costs in a way that's highly inefficient. So really,
the argument is shaped the charge of superintelligence. Another point that is made that thing is very
important that we flow throughout this is a shift of instead of paying people for hours of work,
paying people instead for solutions they deliver. So if you're a law firm, if you're
hiring a law firm for interblocks and out of you contracts, the new world is not paying them
through you contracts. It's paying them for delivering an air-free, legally tight agreement period.
It's verified outcomes. And we're going to flow this through out. I mean, this is a change,
I think that's going to hit less like a wave, where it's going to transform. You're
only going to be hiring companies and AI systems that are delivering you definitive verified
outcomes. That's right. And one of the, one of the most, I think,
egregious inefficiencies that one might see throughout the economy right now is people paying
for the inputs when they should be paying for the outputs paying by the person hour for labor,
when you should be paying by the achievements of whatever the economic system is. And I think it's
only by moving to this sort of performance or outcome-based economic mindset that we get the
all the benefits of abundance. So I feel it's really two chapters or two thoughts and one
section called the thesis. You know, one is ASI as inevitable. The other is really compelling,
which is the, the shaped charge, like it's really dawns on me that graphical stuff, the holiday,
the virtual girlfriend are very compute intensive and solving a disease or solving physics
is actually not any more compute intensive than one person's virtual girlfriend. And so the
choices on how to use our very limited amount of compute over the next year's years are critical,
critically important, and there's no focus. Yeah, I love the fact that you're taking this on
because there's no body of authority right now that's even thinking about it that has an eight power.
So I hope we'll act like a lot of people up. You've articulated it beautifully, Dave.
So, yeah, so anyway, I've got, I've got a couple of points here. So I think saying the
cognition is a cheap commodity is fabulous. I think it's really important. And the use of that
in solving kind of big problems is really, really important. I think it's great to say let's
evaluate and reward outcomes rather than rewarding work. I've got to push back on the ASI's
inevitable thing. That's like a philosophical statement rather than scientific. I think that
weakens the paper. I'd rather you say something like incentive structures, given the current
incentive structures, scaling intelligence is a much more important attractor state, right?
Because that will then lead you to where you want to get to. I would say, I mean, I think it's an
interesting point to be sure, but I think there's almost an instrumentally convergent trap
that I see a lot of frontier labs, or at least partially fall into, which is, okay, we have super
intelligence, at least baby super intelligence right now. How do we allocate it? What in particular,
what fraction of our compute budget, if you're a frontier lab, do you allocate to building the
perfect AI researcher that can recursively self-improve, as we talk about an almost every episode
of this point, versus how much of your compute budget, which is scarce, do you spend solving
everything else? And I think that that's sort of the fundamental quandary, or how much do you sort
of reinvest in recursive self-improvement versus now, finally, using at least some of the compute
to solve everything else. And I think solving that asset allocation question is key, and then within
everything else, how do you distribute it? That's not a big. Peter's law, which has given the choice
do both. Alex, this is also going to be true for the entrepreneur for the company, right? We're all
going to have compute budgets in the final result. You're going to start mounting compute. You have
access to where do you aim that compute, right? It's a, it's a front, it's a way front that you can aim
in a direction that you want to solve. And when you do that properly, not only enables you, but enables
everybody else to build on top of it. That's right. I'll move us on to chapter three here. And again,
please, there's so much content. We only want you to take a look at this paper and read it.
We're just giving you a quick overview here. The mechanics, Alex, over to you.
Okay. So first, I think in this chapter, we finally definitively address the question that
that I guessed every time I'm making a point about AI solving math, which is what is solving
mean? What does it mean to solve a domain like math? And we provide in the chapter a more thorough
definition, but sort of heuristically, the shorthand is to solve a domain means that you can get it
to the point where you can just pour compute on and problems get solved. It means that you can
scaleably, you have all the architectural pieces in place. And I'll talk in one second about what
the architecture looks like or should look like. But you have enough of the architecture in place
that you can scaleably literally pour more compute on and get more solutions out within that
domain. So that's, for avoidance of doubt, when I talk about solving math or solving physics or
solving other domains, that's what I'm talking about. Second point, yes, please. I would just say,
Alex, on that, it's no longer the domain of a single genius to work on something and I hope they
got it right. The AI compute, as you said, it's a matter of where you want to shape the aim
that shape charge. That's right. We're seeing the industrialization of cognition and the bulk
solution of multiple fields. I should also add parenthetically, I guess, as a preliminary matter
on this narrow topic, I also have a portfolio company named physical superintelligence that's
trying to solve all of physics with an approach like this just for full disclosure purposes.
The architecture involved, so several layers, you need a purpose that's like the objective
function or the goal. You need a task taxonomy, which is essential. You need a suite of tasks
that are going to be solved. It's almost the map of the terrain that you're going to solve.
And when we talk about making sure that compute is being used efficiently and wisely as a targeting
system or through the lens of a targeting system to solve lots of problems, the task taxonomy is
absolutely essential. Third, observability, you need raw data from data streams or sensors that
you're going to use to adjudicate whether you're making progress. Fourth, you need the targeting
system itself. So I've argued on this podcast and elsewhere many, many times, we need more harnesses.
We need more benchmarks in order not just to make sure that we're making progress, but actually
shape the charge and shape the progress. Many AI techniques depend on benchmarks and emails
in order to make progress in a given field. The next item, the model layer, the most obvious one,
we need models. We need AI models that are capable of functioning as a virtual brain for
solving problems. Unfortunately, those are improving pretty rapidly. Next, we need modes of
actuation. It's insufficient for us to just know this television commercial as well. I stated
a holiday and express at night. Therefore, I know how to solve the problems similar idea here.
Maybe that's a bit too cool. I don't know. We need modes of actuation. So hands and APIs that
are able to reach out into the physical world or the virtual world or the biological world and
have and shape the impact on the world given better ideas coming from the AI's. And then,
we need better modes of verification, red teaming governance distribution. That's what we call
the industrial intelligence stack. So, whereas previously during the industrial revolution,
we might have spoken about rotors and combustion engines and various forms of electron mechanical
systems. These are the key components. I think the key layers of the intelligence revolution.
You know, the alpha-4 entrepreneurs here is we've talked about, you know, these waves of solving
areas and problems, right? We're about to flip math, coding, physics. So, your job that was
entrepreneur is to figure out which industry is about to make this flip. And where do you focus
your compute wallet on making that, right? And how do you help solve an area of passion to you?
Dave, so aim. I kind of curious whether, you know, I'm used to launching a couple hundred
agents, maybe 250 agents, 250 six agents actually to work in parallel on a problem. And if the scaffolding
that you're describing is right, it comes back just perfectly solved and if it's even slightly flawed,
you have, you know, a $2,000 bill and a bunch of crap. How much are you spending per day on those
agents, Dave? Yeah, well, it's a hundred bucks every few minutes popping up on my screen here.
It's not, it's not quite that bad. It does seem like it's every minute, but it's not.
But I'm curious, you know, to what degree this is actual engineering, these five layers are
true scaffolding, like this is hard code, or is it more conceptual?
I think it's a balance of both. I also think it to some extent is a trick question because
increasingly the harness and the scaffolding itself is being generated by the models. So to the extent
that we're in the era of recursive self-improvement, this entire architecture is itself an artifact
a downstream product of itself. Yeah. Yeah, I think I totally agree, and I also think that's the path
to insanity because I at some point you have to say, this is hard code because you know,
then go the eye will invent the next thing and the next thing, it goes to infinity and then
years like you lose your mind. But I would say also that this is, in my mind, the way we prevent
insanity in an era of recursive self-improvement is with these benchmarks targeting systems that
make sure that as systems are recursively self-improving, we can quantitatively measure
what are they optimizing towards? Are they going in a constructive direction or not?
Yeah. Chapter four, the lock. Wait, wait, wait, wait, I've got a couple of comments here.
If you can go back as a slide, can I? Yeah, exactly. So I think the, I really love the
shift from genius to logistics because as you move, you can, you always kind of say,
take something for a more black art and make it a prescriptive process and when you can do that,
that's awesome. I think that's fantastic. I have an issue with your, you know, maturity levels
because you call it like natural law, but it's really just a taxonomy. We've had lots of
industries get stuck at different levels like autonomous driving, et cetera, et cetera. So this
feels like a framework retrospectively imposed on what's going on. I think it's great aspirationally,
right? But some of them, because it's calling you a maturity curve, kind of speaks of
an inevitability to it, which that may not be exactly the case. It's more of a descriptive model
than a predictive one. Yeah, I would say any good theory of history and and solve everything is
in part not just a theory of the future, but a theory of history and how revolutions have worked
in the past inevitably, you know, as Monty Python says, it's only a model. So I do think
there is an element of model building here where we're trying to, for the first time, articulate
a self-consistent coherent theory of how this is all supposed to work, how is the singularity
supposed to play out over the next 10 years? And to your point, Celine, about autonomous.
Alex, I could say not only how it's supposed to play out, but how do you have it play out
in a way that leads us towards abundance versus towards a model? Normatively, how should it
play out and not just how will it play out? But I think one, you know, at the margins, one can
quibble well, actually there are seven maturity levels for industries to evolve through their
industrial intelligence stack, or it's a continuum. But I think the central point stands
regardless of how one sort of splices hairs on maturity levels that we're seeing over and over
again, and we can get into more detail on this. We're seeing domain after domain, industrial
vertical, after industrial vertical succumb to basically the automation of intelligence, which used
to be the province of individual artisanal loan innovators, and it's just becoming an industrialization
of intelligence. All right, I'm moving on to the next chapter, chapter four. I'm sorry,
keeping us moving the lock-in, Alex. So in this chapter, we talk about, in part,
alpha-fold three from Google DeepMind and argued that that was a template for entire collapses of domains
that almost overnight, and I've made this point on the pod in the past, alpha-fold three took
the problem of determining the structure of a protein, which used to require a biology PhD student
five plus years of time, laborious venture work, just to determine the structure of a single
program, and almost overnight, alpha-fold three solved that problem across many millions of proteins
known and unknown. That's the, in my mind, like the prototypical example of a domain collapse,
and we argue in this chapter that we're now in a phase of a history, a future history,
where this is just going to start to happen over and over again across different fields, where
intelligence shifts from an artisanal craft to a utility that just flows, and we argue that we
have approximately 18 months or so to decide what direction to shape the flow in, and to set the
standards for how this is going to be done at scale, given that we are dealing with scarce compute,
to put in place the supply chains, which are huge, and we talk about on the pod all the time,
about all these supply chain scarcity issues, memory chip crises, GPU crises, what happens to Taiwan,
what happens to the semiconductor fabrication facilities in the U.S. versus not in the U.S.
And then all the data rights, this is where we're in a critical 18, we argue 18-month period
when all of these details are going to shape the intelligence explosion, and so we want to
make the best decisions in the next 18 months. I can't wait for this chapter, actually 18 months,
you think it's such a short timeline. Another important point here for CEOs listening,
for entrepreneurs listening, is the race isn't about building the best AI, it's about writing
the best scorecard that everyone else has graded on, so what does that mean? Today's health
care system, and it's an example Alex, you use beautifully. Today's health care system,
the benchmark is the number of patients' process per hour, which means it's driving a lot of
short visits with the position and cost economics driven, but what if the benchmark instead were
patients who were still healthy five years from now? That would set up a whole different set of
optimization outcomes. So writing the scorecard that your AI system is going to use to measure
success is critically important. So why is this chapter called the lock-in? Exactly. Are you
implying that the decisions we make in the next 18 months have locked in humanity for the rest of
time and the path? Maybe not for the rest of time, but that is the inspiration for the name,
that we're in a period inspired in part by a kneeling of a metal cooling that the decisions
that we make now are at least going to lock in a chunk of our future like cone. Yeah, make sense.
Totally make sense. Absolutely. You know, took the courty keyboard. It was decades of lock-in,
so I think it is. But I do like the... We're stuck on the courty keyboards. I mean, this is
what we can have the singularity and you'll still be longer. How long before we get past that
and could we stop you? But anyway, I really like the alpha-fold example demonstrating a domain
collapse, right? That's like really great. But you're here, you're talking about lock-in as a like
as a technical inevitability. But this is at many times a policy and a governance choice,
right? It's monopolistic APIs. It's closed data. It's regulatory capital. There's lots of other
stuff because how do you distinguish between like bad lock-in and productive outcomes? That's tough.
I mean, there's... You're perfect world or they're like five jurisdictions with different
choices and then at least we have variety or is it inevitable that there's just one lock-in?
I think, I mean, in some sense, that's the grand geopolitical question that we, as we just
not a normative answer, but just a descriptive answer, it seems like we're heading to a
near future where there're going to be multiple spheres or zones of influence each able to
independently lock itself in. So to the extent that we, with this call it an extended essay,
can have any influence. I think the aspiration is to have a positive, constructive influence on
all of those spheres of influence and not just the one.
By the way, I disagree with the 18 months when I've been advising some big company CEOs,
I've been saying two years. So, you're pulling a reverse Moore's law. Remember Moore's law started
as 18 months became 24 months. You're pulling a reverse Moore. Because if you have the next meeting
six months from now, it's going to add that six months time. Let's go. All right, let's go to chapter five
here. The mobilization in Alex, if it's okay with you, the last three chapters of this paper or
the most important. I want to hit on chapter five and six and then really focus on seven, eight, nine.
So, give us the summary on mobilization, if you would. All right. So, the idea with this chapter is
spelling out a future timeline for how a call it a wave front of the explosive shock of the
intelligence explosion was going to propagate from math, which we talk about on the pod all the time,
over the next couple of years to the physical world, physics, chemistry, material science, biology,
and then through the end of the decade toward planetary systems, vision, fusion, the
Dyson Swarm by the early 2030s. Amazing. And chapter six, the engine.
Yes, so this engine is very practical and talks about how to design the targeting systems,
the benchmarks at a sufficient level of rigor that readers and folks all over the world can implement it
with some level of confidence. You know, the point we made here is, you know, don't invest in the
AI models. If you look into the train and train track analogy, the trains are becoming commodities,
it's the tracks, right? The tracks that the trains run on, the scoring systems, the testing
infrastructure, the data systems, the funding mechanisms. And they're laid out beautifully here.
Those are the elements that are the most important for entrepreneurs and CEOs we're focusing on.
That's right. Let's go to chapter eight, one of my seven, one of my favorite moonshots.
So here in maybe Peter, you want to speak to this one, perhaps even more than I do, we lay out
15 different moonshot level missions for what we argue are good uses, maybe optimal uses,
for this targeting system capability as we start to channel superintelligence into productive
applications, maybe Peter, I'll pass it back to you for your favorites. Sure. So the thought is,
you know, we many of us have discussed exprise over the time. The notion is that there's these
giga exprises. These massive opportunities on a humanity level scale from printing human or human
organs to achieving fusion to understanding the fundamentals of unified field theory and physics.
And it's where do you as an entrepreneur or you as a CEO or head of an organization want to
focus this incredible superintelligence that's coming to take moonshots? I keep on saying,
you know, in the educational field, if you're using AI as a ninth grader to solve a ninth grade
homework assignment, you've lost it, right? If you're using AI to build starships, that's it.
So how do we as humanity go after problems that we would have never imagined or capable of doing?
And so the chapter lays out 15 different moonshots just to get creative juices going to say,
these are capabilities that we're going to be able to bring to bear to solve these moonshots.
So can you list out a couple of the moonshots? Sure, for the viewer. And one of my favor
ones is interest species communication. I have a soft spot for that. We talk on the pot all the time
about uplifting nonhuman animals. And I think as we start to think and maybe somewhat
controversially about what future forms of personhood might look like. I think solving problems
like interest species communication or solving hard problems and physics. Those are those
definitely have soft spots in my heart. Yeah, I think it's making humanity a multiplayer
species. It's getting too lunch of escape velocities. It's all of the things, you know, it's
it's basically speed running all the science fiction movies. The positive, not dystopian science fiction
movies. That's right. Yeah, you know what I love about this is if you look at John F. Kennedy
and going to the moon, the brand of fact, enabling somebody in power like John F. Kennedy to
attire the brand of the mission back to them. That's critically important for them to then
inspire the world that this is important. And I think what we did wrong is our governor
here did an incredible job of unleashing $3 billion from the legislature to try and become an AI
leader. But it was too vague. It's like, what does it mean? So the money hasn't even been deployed.
But if you tie it to these 15 moonshots, and then the governor says, we want our state to win
this race like John F. Kennedy did to the moon. They can pick the one they're passionate about
unleashing. And we have 50 states, you know, they can all choose their favorite of the 15,
maybe not talking to aliens, but whatever one they they latch on to. It's such a really great
framework. I'll just listen to it. I'll just list some of them like W human lifespan
is one ending hunger with synthetic food systems around the world is another AI empowered
education for all at the highest possible level. Right. It's a high bandwidth BCI. We've been talking
about that on this on this pod for a while now. Demonstrating human mind uploads can't wait
for that. Plan B, maybe Plan C, we'll see, you know, as Alex said in her species communications
understanding human consciousness. I think we've talked about that previously, you know,
can we understand human consciousness at which point maybe will understand consciousness
for our AI systems as well. So, you know, what have we dreamed about? Another one I love is
disaster prevention and avoidance, predicting earthquakes, and then preventing them.
Or tsunamis, as a case might be, right? These become natural surprises, you know.
They are, they're, they're what I call giga-exprises here. But I think one of the important
things in this chapter is allowing people, in fact, demanding people dream bigger than ever before,
because the tools we have to solve the biggest problems are now, are now epic.
I think this for me is the most powerful part. The fact that you can say anybody has the agency now
leveraging these tools to go after these, what seem like impossible things become wrote.
You're only limited now by your imagination. And I think that's it. And you're compute budget.
And you're compute budget. Yes. But, you know, that's dropping 90 percent a year, so we're in good shape.
That's right. All right. The model versus the machine. And at first, Alex, when you
go and you propose, model as a term, I was like, I'm actually like, and now I love it.
So, describe what the model is. Yeah. So, the model is the another term might be the bureaucratosaurus
that loves to measure inputs rather than outputs and slow down progress. And the idea is
without properly shaping the charge of the intelligence explosion, the model is the end state
that we find ourselves when sort of basically muddling our way through is one of the
the atomologies of that term. So, what we talk about in this chapter in a single sentence is what
happens after we win, painting a positive and nondistopian view of, in particular, what does
human agency look like? I made this short film posted to social media called a nation that
learned to sprint, depicting what life in the early 2030s might look like if everything goes well.
And we see GDP, 2xing or 3xing year over year. And what does a human quote unquote,
job even look like in a macroeconomic scenario like that? So, in this chapter, we lay out
lots of new job opportunities, career opportunities that will be available to humans, at least
unated humans. So, target designers, for example, or data rights brokers, people who are involved
in shaping the targeting systems and shaping how we aim, fire, and verify super intelligence towards
the hardest problems that humanity faces. This is going to be a growth industry from a job perspective.
Another point we make in the chapter here that super important we've discussed in
Salemium, I've discussed this before, is that GDP is a terrible mechanism for measuring economic
health. Paper proposals replacing GDP was something called the abundance capability index,
which is measuring a nation's capacity to solve problems rather than how much money
changes hands. So, I think, again, as we look at benchmarks, as we look at rails and harnesses,
understanding this is really important. I think also a challenge here, though, is, you know,
it's UBI, UBC, whatever we want to call it. It's a great endpoint and a great aiming point,
and you want to have a target, as you say, Peter, otherwise you'll miss it every time. The challenge
is moving from a welfare taxation, labor, union structure to that, such a huge leap. I have no
confidence in public sector and getting us there. So, how do you navigate that? I think that's
something worth exploring. I mean, that's what a scope of your thing, but that's a huge consideration.
I was going to say in what a wonderful transition. Thank you to the last chapter.
Build the rails. Building the rails, chapter nine. I think one of the most important chapters
of the entire paper, Alex. Yeah, so this chapter is where we lay out the answer to Salemium's
questions. So, what's this so what? And what do you do? If you're not running a nation state,
what can you do? How are you empowered to shape this transition, to shape your own moonshots,
and to control your own targeting system? So, we lay out various suggestions from investors,
as indicated in the slide, funding the primitives, not the applications. There's so much
infrastructure that can and arguably should be built out. If you're an entrepreneur, you should be
building, picking your own targets with the targeting system, create your own benchmarks,
and aim your own compute. If you're an executive of a large company, you should be measuring
the outputs, not measuring the inputs. Dave, I think you put it beautifully earlier in this episode,
talking about the APIification of large corporate boards and corporate governance. I think that's
exactly the right playbook here. And the missing factor is having a benchmark to measure
a corporate objectives in such a way that the problem of corporate governance becomes a matter of
maximizing the use of available scarce compute to maximizing those KPIs and those EVEL. So,
in this chapter, we lay up for a variety of different roles in the economy. What can you do?
What can you in the audience do to help us achieve a utopian vision of abundance and post-scarcity
and excellent use that's use social for super intelligence? So, I want to wrap this here. I want to
encourage all of our listeners to put the link to the paper down below. It's solved everything.org.
Please take a look, load into your favorite LLM, have a conversation with Alex and to some
degree myself, but I credit Alex, is what's the vision for the decade ahead that's going to
bring us to abundance? How do you do it? How do you lead as a leader, as an entrepreneur, as a CEO,
as a governor? Where are we going? And it's going to move much faster. And I think one of the points
here, Alex, is that there's going to be such a distinction between those who do and those who don't
that it's going to create a sort of a 66 million year ago asteroid strike that's going to kill
the dinosaurs and elevate the furry mammals, say, furry lobsters moving forward. Now, we love our lobster friends.
He didn't mean that. Peter really didn't mean that. Elevate our lobsters, let me say that. Elevate
them into lower thore bit. All right, favorite part for all of us AMAs. I'm going to keep us to
one question per mate. All right, so here they are. They're in nine of them. Let's say,
Dave, do you want to pick first? Sure. I like number three, because it's such a happy answer.
In a world with perfect AI output, will there still be a place for human spark in art and sculpting?
Will hand-made work have higher value or be buried in the AI humanoid production?
Wholeheartedly believe it'll have S, dramatically higher value. Human touch, it will be so
rare and so valuable, but also abundance of capital will be unbelievable. And so I expect artwork
current artwork is one of the best investments you can make right now, but going forward
is a category. It will go up tremendously in value and people will appreciate all things human,
whether that's human action, human sports, human poetry, human artwork, sculpting. I expect to be
definitely a rising area for sure. I think that would be a great
conversational code debate, but for our next pod to make what is going to be most value from
humans in the future. Celine, do you want to pick one of these? Let's see, I would pick number five,
right, which is how is a young person supposed to earn an income when they compete against a model
a cost $50 a month? That's from at Plan P's D. The it's a great question, but you're assuming
the future's about competing with AI. It's about directing it and leveraging it and amplifying
yourself with it. In history, we've destroyed all the jobs that we've created control points
and we've done orchestration, we've done intent. So winning isn't productivity, it's agency.
And we talked about this earlier in the positive, like knowing what to do and why it matters
is more important. How do you mobilize intelligence at scale is really the biggest challenge?
And you can do that today in a way that you can't do ever. We've been doing workshops with
teenagers and showing them how to use AI as a superpower to give themselves the agency.
And I think that's where I would go with that. Alex, would you pick one of these?
All right, I like this assortment. So I'll pick number eight for 100 trillion.
Question number eight is, with AI taking tasks, we do ourselves. Isn't there a risk? We lose
essential skills and become completely dependent on AI services. And that's asked by Joanne Hoffs.
So I want to invoke my friend, John Smart, hope you're listening. John has, I think a brilliant
dictum that the first generation of any new technology is dehumanizing. It takes away all your skills.
The first generation of calculators take away your arithmetic skills. Second generation is net
to humanity. Third generation is another friend of the pods. Even Wolfram Mathematica gives you
new superpowers, gives you new skills. So I don't accept the premise that there will be any sort
of permanent loss of essential skills due to AI automation. I do think that there is a short-term
substitution effect where AI drives down the cost of various skills or various tasks. But
over the long-term, I expect AI automation to be net superhumanizing. We're going to
to be capable of so much more with AI than we can do otherwise without it. And I'll also say,
Werner Vingy is written quite a bit about this. Definitely encourage everyone to read
Rainbows End and Fast Times at Fairmont High, novel and novella respectively that
talk about this at Nazium. We're going to, I think, find ourselves in a very near-term future where
just like there's wilderness camp to learn how to survive without modern technological aids.
We're going to start, I think, in our educational system, at least the better parts of it,
having the moral equivalent for wilderness camp for AI, where all of your AI tools get taken away.
You have to do things manually just so that you at least have that skill set. And then you get all
your AI skills back in every, every fourth grader becomes a Nobel laureate.
I love that. All right, I'm going to club this out with number six. I use Claude Daley,
it fails in basic consistency, I think, is saying, how can this be close to AI when I have to check
every output for errors that's from MMGP90T? So, I'm going to say again, AI is the slowest and most
incorrect, it will ever be. I know when I'm using my Claude bot or Claude 4.6,
if I get something that seems off, I will ask it to check itself and being able to use this
and recursive fashion. Also, MMGP-T9 were in a period of recursive self improvement. I think
where this steepest part of the curve and it's going to become more and more capable every day.
And the idea that we can use AI is to check AI's and, in fact, to do deeper reasoning is
going to eliminate this very quickly. Okay, let's jump into our outro music. This is from
friend of the pod, CJ Trueheart, CJ, thank you for this. CJ was on a Zoom AMA, that's Steven
Kotler and I did for our book, we are as gods and he actually wrote this as a result of that AMA.
Anybody who is a creative, we love creatives and if you want to send us outro or intro music,
send an email to media at DMandis.com, myself and a team are reading it and we'd love to get
your input and we'd love to play it. All right, let's enjoy this outro music from CJ Trueheart.
This singularity is now, now the singularity is here and it's not asking permission. It's asking
you a question. What you paying attention to? Are you paying attention? Or are you paying the
price scrolling through a sea of sex in an attainment twice? You can be a creator or you can be
consumed every hour that you waste is a future left in tomb. The hands you you be eye call it
containment. A golden leash, a velvet cage, a comfortable arraying wake up the moments here to
open your eyes. Your dreams are close enough to touch the skies. The deepest problems that have
plagued you in disguise. Only you know that pain. Only you can make it fly.
So what do you see? When you look in the mirror, do your actions match the vision? Is the picture
getting clear? Why wait when the time is here? Why wonder when the path is clear? Why sit as a
passenger when you have the power to steer? Attention is the currency.
Don't let it be the cage.
The future for some will pass them by. What others don't ask how? They ask why not now. Not
some day, not somehow. They ask why not now. See everybody wants to live a star track
dynasty, but nobody wants to rise with a purpose they can see. Same old, same old, comfortable and
cold, trading in their potential for a story, already told. Hence is only you can know it's just a
question of who you choose to show. Up is today tomorrow, every dawn, every day. The version that's
slow faded or who you choose to be today. So what do you see? When you look in the mirror,
do your actions match the vision? Is the picture getting clear? Why wait when the time is here?
Why wonder when the path is clear? Why sit as a passenger when you have the power to steer?
Attention is the currency. Don't let it be the cage.
See, I've lived in the dark. Lost in the world, lived in poverty, but the bottom didn't break me.
It revealed the deeper me. Those who face no challenge will embrace no change. Those who embrace
no change will always stay the same. And those who stay the same get left behind. Hold them
pocket change because they refuse to learn. They refuse to turn what they gave their attention to.
So attention became their chain, but I turned my pain into a plane. And I'm never letting
back on that terrain. All right, thank you CJ. Guys, I've been half of skipping my lobster,
sending you guys an incredible week ahead. And as always, love it. Alex, it was an honor and a pleasure
to work on solve everything with you, excited to get it out to the universe. I think the value
of steering people toward this accelerating time and how they actually have the biggest impact on
creating abundance and not the model is critically important. Great Peter.
Sled pleasure writing it with you as well. And I would encourage all of the humans and non-humans
in our audience to read it and let us know what you think. Yes, for sure. All right, WTF twice a week
at these days. Thank you to our subscribers. It's free, please subscribe. We'll let you know
when the episodes drop. Tell your friends about this. I've been here at, you know, 20 Robins
event. And yeah, I would say probably 100 people have come up and said, oh my God, I love moonshots.
And everyone, I love Alex. Alex, you've got fans here in Sunbell.
How many of those people were human Peter? Unfortunately, they were all human, at least for the
moment. Yeah, all right, Dave Salim. Thank you, guys. If you made it to the end of this
episode, which you obviously did, I consider you a moonshot mate. Every week, my moonshot mate
and I spent a lot of energy and time to really deliver you the news that matters. If you're
subscriber, thank you. If you're not a subscriber yet, please consider subscribing so you get
the news as it comes out. I also want to invite you to join me on my weekly newsletter called
Metatrends. I have a research team. You may not know this, but we spend the entire week looking at
the Metatrends that are impacting your family, your company, your industry, your nation. And I put
this into a two minute read every week. If you'd like to get access to the Metatrends newsletter
every week, go to dmnds.com slash Metatrends that's dmnds.com slash Metatrends. Thank you again for
joining us today. It's a blast for us to put this together every week.
Ready to relax in your dream bathroom treat without the stress of figuring out every detail
yourself? At the home depot, your bath upgrade is covered. Shop fully designed rooms and curated
bath collections to go from inspiration to transformation fast. Savings have up to 40% will make it
easier on your budget and find everything you need. From tubs to toilets and all the tile in between
to bring your vision to life. The home depot, dream baths built here.
